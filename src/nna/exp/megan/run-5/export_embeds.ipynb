{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /home/enis/projects/nna/src/nna/exp/megan/run-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/enis/conda/envs/soundenv3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import torchaudio\n",
    "torchaudio.set_audio_backend('sox_io')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nna import dataimport\n",
    "from nna import fileUtils\n",
    "from nna.exp import runutils\n",
    "\n",
    "import modelarchs  # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def repeat_data(data, expected_len) -> np.ndarray:\n",
    "    '''pad by zeros if it is not divisible expected_len seconds.\n",
    "    '''\n",
    "    sr = 48000\n",
    "    left_over = (data.shape[0]) % (expected_len * sr)\n",
    "\n",
    "    if left_over != 0:\n",
    "        missing_element_count = (expected_len * sr) - left_over\n",
    "        padded_data = np.pad(data[-left_over:], (0, missing_element_count),\n",
    "                             'constant',\n",
    "                             constant_values=(0, 0))\n",
    "        return np.concatenate([data[:-left_over], padded_data])  # type: ignore\n",
    "    else:\n",
    "        return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pathMap():\n",
    "    def __init__(self,model_relative_path=None) -> None:\n",
    "        scratch = '/scratch/enis/data/nna/'\n",
    "        home = '/home/enis/projects/nna/'\n",
    "        self.run_id = 'run-5'\n",
    "        self.exp_dir = f'/home/enis/projects/nna/src/nna/exp/megan/{self.run_id}/'\n",
    "        self.clipping_results_path = (scratch +\n",
    "                                         'clipping_info/all-merged_2021-02-10/')\n",
    "        self.output_dir = scratch + 'real/'\n",
    "        self.file_properties_df_path = scratch + 'database/allFields_dataV4.pkl'\n",
    "        # model_path= ('/home/enis/projects/nna/src/nna/exp/megan/run-3/'+\n",
    "        # 'checkpoints_keep/glorious-sweep-57/best_model_56_ROC_AUC=0.8690.pt')\n",
    "        checkpoints_dir = scratch + f'runs_models/megan/{self.run_id}/checkpoints/'\n",
    "        if model_relative_path is None:\n",
    "            self.model_relative_path = 'comic-sweep-29/best_model_20_min_ROC_AUC=0.7202.pt'\n",
    "        else:\n",
    "            self.model_relative_path =model_relative_path\n",
    "#         self.model_relative_path = 'warm-sweep-160'+'/'+'best_model_11_min_ROC_AUC=0.7076.pt'\n",
    "    \n",
    "        self.model_path_name = self.model_relative_path.replace('/','_')\n",
    "        self.model_path = (\n",
    "            checkpoints_dir +\n",
    "            self.model_relative_path)\n",
    "        self.out_csv_file_name = scratch+ f'labeling/megan/AudioSamplesPerSite_post/{self.run_id}_{self.model_path_name}_labels_v0.csv'\n",
    "\n",
    "\n",
    "\n",
    "def setup_inputs(args):\n",
    "    index, count = int(args.index), int(args.count)\n",
    "\n",
    "    region_location = [['dalton', '01'], ['dalton', '02'], ['dalton', '03'],\n",
    "                       ['dalton', '04'], ['dalton', '05'], ['dalton', '06'],\n",
    "                       ['dalton', '07'], ['dalton', '08'], ['dalton', '09'],\n",
    "                       ['dalton', '10'], ['dempster', '11'], ['dempster', '12'],\n",
    "                       ['dempster', '13'], ['dempster',\n",
    "                                            '14'], ['dempster', '16'],\n",
    "                       ['dempster', '17'], ['dempster',\n",
    "                                            '19'], ['dempster', '20'],\n",
    "                       ['dempster', '21'], ['dempster',\n",
    "                                            '22'], ['dempster', '23'],\n",
    "                       ['dempster', '24'], ['dempster', '25'],\n",
    "                       ['ivvavik', 'AR01'], ['ivvavik', 'AR02'],\n",
    "                       ['ivvavik', 'AR03'], ['ivvavik', 'AR04'],\n",
    "                       ['ivvavik', 'AR05'], ['ivvavik', 'AR06'],\n",
    "                       ['ivvavik', 'AR07'], ['ivvavik', 'AR08'],\n",
    "                       ['ivvavik', 'AR09'], ['ivvavik', 'AR10'],\n",
    "                       ['ivvavik', 'SINP01'], ['ivvavik', 'SINP02'],\n",
    "                       ['ivvavik', 'SINP03'], ['ivvavik', 'SINP04'],\n",
    "                       ['ivvavik', 'SINP05'], ['ivvavik', 'SINP06'],\n",
    "                       ['ivvavik', 'SINP07'], ['ivvavik', 'SINP08'],\n",
    "                       ['ivvavik', 'SINP09'], ['ivvavik', 'SINP10']]\n",
    "\n",
    "    return region_location[index:index + count]\n",
    "\n",
    "\n",
    "def setup(args,config=None):\n",
    "\n",
    "    pathmap = pathMap(model_relative_path=args.model_name)\n",
    "\n",
    "    os.chdir(pathmap.exp_dir)\n",
    "\n",
    "    file_properties_df = pd.read_pickle(pathmap.file_properties_df_path)\n",
    "\n",
    "    device = 'cuda:' + str(args.gpu)\n",
    "    device = torch.device(device)\n",
    "\n",
    "    CATEGORY_COUNT = 9\n",
    "    # '1.1.10','1.1.7'\n",
    "    maxMelLen = 938\n",
    "    ToTensor_ins = modelarchs.ToTensor(maxMelLen, 48000, device)\n",
    "    transformCompose = transforms.Compose([\n",
    "        ToTensor_ins,\n",
    "    ])\n",
    "\n",
    "    h_w = [128, 938]\n",
    "    \n",
    "    if config is None:\n",
    "        config = {}\n",
    "    config['label_names'] = ['1-0-0',\n",
    "                            '1-1-0',\n",
    "                            '1-1-10',\n",
    "                            '1-1-7',\n",
    "                            '0-0-0',\n",
    "                            '1-3-0',\n",
    "                            '1-1-8',\n",
    "                            '0-2-0',\n",
    "                            '3-0-0',\n",
    "                            ]\n",
    "    #warm-sweep-160/\n",
    "    config['v_str'] = 'multi9-V1'\n",
    "#     config['fc_1_size'] = 64\n",
    "#     config['CNN_kernel_size'] = 12\n",
    "#     config['CNN_filters_1'] = 6\n",
    "    config['expected_len'] = 10\n",
    "    config['device'] = device\n",
    "    \n",
    "#     #dandy-sweep-196\n",
    "#     config['v_str'] = 'multi9-V1'\n",
    "#     config['fc_1_size'] = 71\n",
    "#     config['CNN_kernel_size'] = 12\n",
    "#     config['CNN_filters_1'] = 16\n",
    "#     config['expected_len'] = 10\n",
    "#     config['device'] = device\n",
    "    \n",
    "#comic-sweep-29\n",
    "#     config['v_str'] = 'multi9-V1'\n",
    "#     config['fc_1_size'] = 64\n",
    "#     config['CNN_kernel_size'] = 12\n",
    "#     config['CNN_filters_1'] = 6\n",
    "#     config['expected_len'] = 10\n",
    "#     config['device'] = device\n",
    "\n",
    "    output_shape = (CATEGORY_COUNT,)\n",
    "\n",
    "    model_saved = modelarchs.singleconv1dModel(\n",
    "        out_channels=config['CNN_filters_1'],\n",
    "        h_w=(1, h_w[0] * h_w[1]),\n",
    "        fc_1_size=config['fc_1_size'],\n",
    "        kernel_size=config['CNN_kernel_size'],\n",
    "        output_shape=output_shape)\n",
    "\n",
    "    model_saved.load_state_dict(\n",
    "        torch.load(pathmap.model_path, map_location=config['device']))\n",
    "    model_saved.eval().to(config['device'])\n",
    "\n",
    "    return model_saved, transformCompose, config, file_properties_df, pathmap\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader_from_array(input_data):\n",
    "\n",
    "    # divide to 10 second excerpts\n",
    "    print(input_data.shape)\n",
    "    input_file_data = input_data.reshape(-1, 480000)\n",
    "    input_file_data = torch.from_numpy(input_file_data).float()\n",
    "    dataset = {\n",
    "        'predict':\n",
    "            runutils.audioDataset(input_file_data,\n",
    "                                  None,\n",
    "                                  transform=transformCompose)\n",
    "    }\n",
    "    dataloader = {\n",
    "        'predict':\n",
    "            torch.utils.data.DataLoader(dataset['predict'],\n",
    "                                        shuffle=False,\n",
    "                                        batch_size=1)\n",
    "    }\n",
    "    return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Arguments():\n",
    "    def __init__(self,index,count,gpu,model_name):\n",
    "        self.index=index\n",
    "        self.count=count\n",
    "        self.gpu=gpu\n",
    "        self.model_name=model_name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region_location = setup_inputs(args)\n",
    "# model_saved, transformCompose, config, file_properties_df, pathmap = setup(args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_audio_files(region_location, file_properties_df):\n",
    "#     '''Load audio files from given regions and locations as Audio dataset\n",
    "#     '''\n",
    "#     region_location_datasets = {}\n",
    "#     for region, location in region_location:\n",
    "#         filtered_files = file_properties_df[file_properties_df.region == region]\n",
    "#         filtered_files = filtered_files[filtered_files.locationId == location]\n",
    "#         filtered_files = filtered_files[filtered_files.durationSec > 0]\n",
    "#         dataset_name_v = '-'.join([region, location])\n",
    "#         audio_dataset = dataimport.Dataset(dataset_name_v=dataset_name_v)\n",
    "#         for i in filtered_files.iterrows():\n",
    "#             audio_dataset[i[0]] = dataimport.Audio(i[1].name,\n",
    "#                                                    float(i[1].durationSec))\n",
    "#         region_location_datasets[(region, location)] = audio_dataset\n",
    "#     return region_location_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/meganLabeledFiles_wlenV1.txt\n",
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite\n",
      "4 files are missing corresponding to excell entries\n",
      "'-> 5 number of samples are DELETED due to ignore_files and missing_audio_files'\n",
      "-> 415 samples DELETED because they are not in the excell\n",
      "\n",
      "-> 0 samples DELETED because they do not have the taxo info coming from excell\n",
      "\n",
      "-> classes that do not have enough data:\n",
      "[REMOVED!]\n",
      "\n",
      "-> classes that have enough data:\n",
      "['other-biophony'] 56.0\n",
      "['other-insect'] 140.0\n",
      "['other-bird'] 661.0\n",
      "['songbirds'] 392.0\n",
      "['duck-goose-swan'] 183.0\n",
      "['grouse-ptarmigan'] 59.0\n",
      "['other-anthrophony'] 66.0\n",
      "['other-mammal'] 0.0\n",
      "['other-silence'] 20.0\n",
      "['unknown-sound'] 2.0\n",
      "['other-aircraft'] 107.0\n",
      "['seabirds'] 1.0\n",
      "['canids'] 1.0\n",
      "['loons'] 29.0\n",
      "['other-car'] 37.0\n",
      "['other-flare'] 11.0\n",
      "['other-rain'] 20.0\n",
      "('-> 0 number of samples are deleted because their taxonomy category does not '\n",
      " 'have enough data.')\n",
      "-> classes that do not have enough data\n",
      "will be REMOVED!\n",
      "-> 97 number of samples are deleted because their length is not long enough.\n",
      "loading from cache at /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_as_np_filtered_v3_int16.pkl\n"
     ]
    }
   ],
   "source": [
    "audio_dataset, _ = run.prepare_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXCERPT_LENGTH=10\n",
    "audio_dataset = run.dataset_generate_samples(audio_dataset,EXCERPT_LENGTH)\n",
    "all_taxo= list({sound_ins.taxo_code for sound_ins in audio_dataset.values()})\n",
    "\n",
    "x_data, y_data, location_id_info = run.put_samples_into_array(\n",
    "    all_taxo, [], audio_dataset)\n",
    "x_data=np.array(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=list(iter(audio_dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamps=[]\n",
    "file_paths = []\n",
    "audio_index=[]\n",
    "for sound_ins in audio_dataset.values():\n",
    "    i=0\n",
    "    for sample in sound_ins.samples:\n",
    "        \n",
    "        day,clock = (sound_ins.name.split('_')[1:3])\n",
    "        year,month,day = day[:4],day[4:6],day[6:8]\n",
    "        hour,minute,second = clock[:2],clock[2:4],clock[4:6]\n",
    "        year,month,day=int(year),int(month),int(day)\n",
    "        hour,minute,second=int(hour),int(minute),int(second)\n",
    "        timestamp = datetime.datetime(year,\n",
    "                                  month,\n",
    "                                  day,\n",
    "                                  hour=hour,\n",
    "                                  minute=minute,\n",
    "                                  second=second,\n",
    "                                  microsecond=0)\n",
    "        timestamp=timestamp+datetime.timedelta(seconds=10*i)\n",
    "        timestamps.append(timestamp)\n",
    "        audio_index.append(i)\n",
    "        file_paths.append(str(sound_ins.path))\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     dataloader = prepare_dataloader_from_audio_ins(\n",
    "#         audio_ins, config, transformCompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     outputs = single_file_inference(dataloader, config, model_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=np.array(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader=prepare_dataloader_from_array(x_data[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs = single_file_inference(dataloader, config, model_saved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(data):\n",
    "    return 1 / (1 + np.exp(-data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73105858, 0.88079708, 0.95257413, 0.11920292])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([1,2,3,-2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3083, 480000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAME MODEL FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def roc_auc_perClass_compute_fn(y_pred, y_true):\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\n",
    "            \"This contrib module requires sklearn to be installed.\")\n",
    "\n",
    "    res = roc_auc_score(y_true, y_pred, average=None)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_per_set = [[\n",
    "    '12', '14', '27', '49', '31', '39', '44', '45', '48', '19', '16', '21',\n",
    "    '38', '41', '20', '29', '37', '15'\n",
    "], ['17', '46', '50', '32', '33', '25', '40'],\n",
    "               ['11', '18', '34', '24', '13', '22', '36', '47', '30']]\n",
    "\n",
    "target_taxo = [\n",
    "    '1.0.0', '1.1.0', '1.1.10', '1.1.7', '0.0.0', '1.3.0', '1.1.8', '0.2.0',\n",
    "    '3.0.0'\n",
    "]\n",
    "multi_label_vector = run.create_multi_label_vector(target_taxo, y_data)\n",
    "\n",
    "\n",
    "\n",
    "def loc_per_set_find(loc,loc_per_set):\n",
    "    i2name={0:'train',1:'test',2:'valid'}\n",
    "    for i,m in enumerate(loc_per_set):\n",
    "        if loc in m:\n",
    "            return i2name[i]\n",
    "\n",
    "set_names=[loc_per_set_find(loc,loc_per_set) for loc in location_id_info]\n",
    "\n",
    "\n",
    "target_taxo_names=[audio_dataset.taxonomy[taxo][0].replace('other-','') for taxo in target_taxo]\n",
    "target_taxo_names_header=('_pred,'.join(target_taxo_names))+'_pred'\n",
    "target_taxo_header = (','.join(target_taxo_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comic-sweep-29/best_model_20_min_ROC_AUC=0.7202.pt\n",
      "(3083, 480000)\n",
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_20_min_ROC_AUC=0.7202.pt_labels_v0.csv\n",
      "[0.69217629 0.68439965 0.3564696  0.68679907 0.80175217 0.62494624\n",
      " 0.62062741 0.58730659 0.6942959 ]\n",
      "[0.7256433  0.7512538  0.723035   0.81626475 0.80800869 0.91174769\n",
      " 0.72019676 0.81818182 0.75679074]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#/scratch/enis/data/nna/runs_models/megan/run-5/checkpoints/\n",
    "\n",
    "\n",
    "\n",
    "config={}\n",
    "res_res=[]\n",
    "for model_name in [ \n",
    "#     'dandy-sweep-196/best_model_68_min_ROC_AUC=0.7063.pt',\n",
    "#  'dandy-sweep-196/best_model_67_min_ROC_AUC=0.7062.pt',\n",
    " \n",
    "#  'deep-sweep-198/best_model_12_min_ROC_AUC=0.7000.pt',\n",
    "#  'deep-sweep-198/best_model_14_min_ROC_AUC=0.6982.pt',\n",
    " \n",
    "#  'fearless-sweep-206/best_model_64_min_ROC_AUC=0.6955.pt',\n",
    "#  'fearless-sweep-206/best_model_66_min_ROC_AUC=0.6975.pt',\n",
    " \n",
    "#  'sweepy-sweep-203/best_model_36_min_ROC_AUC=0.7025.pt',\n",
    "# 'sweepy-sweep-203/best_model_37_min_ROC_AUC=0.7036.pt', \n",
    " \n",
    "#  'visionary-sweep-121/best_model_145_min_ROC_AUC=0.6967.pt',\n",
    "# 'visionary-sweep-121/best_model_148_min_ROC_AUC=0.6976.pt',\n",
    " \n",
    "#  'warm-sweep-160/best_model_10_min_ROC_AUC=0.7065.pt',\n",
    "# 'warm-sweep-160/best_model_11_min_ROC_AUC=0.7076.pt',\n",
    "                   \n",
    " 'comic-sweep-29/best_model_20_min_ROC_AUC=0.7202.pt',\n",
    "# 'comic-sweep-29/best_model_24_min_ROC_AUC=0.7188.pt' \n",
    "]:\n",
    "    \n",
    "    print(model_name)\n",
    "    \n",
    "    if 'dandy-sweep-196' in model_name:\n",
    "        config['fc_1_size'] = 71\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['CNN_filters_1'] = 16\n",
    "\n",
    "    elif 'deep-sweep-198' in model_name:\n",
    "        config['CNN_filters_1'] = 5\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['fc_1_size'] = 84\n",
    "    \n",
    "    elif 'fearless-sweep-206' in model_name:\n",
    "        config['CNN_filters_1'] = 5\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['fc_1_size'] = 115\n",
    "        \n",
    "    elif 'sweepy-sweep-203' in model_name:\n",
    "        config['CNN_filters_1'] = 12\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['fc_1_size'] = 87\n",
    "    \n",
    "    elif 'visionary-sweep-121' in model_name:\n",
    "        config['CNN_filters_1'] = 4\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['fc_1_size'] = 84\n",
    "    elif 'warm-sweep-160' in model_name:\n",
    "        config['CNN_filters_1'] = 9\n",
    "        config['CNN_kernel_size'] = 10\n",
    "        config['fc_1_size'] = 110\n",
    "        \n",
    "    elif 'comic-sweep-29' in model_name:\n",
    "        config['fc_1_size'] = 64\n",
    "        config['CNN_kernel_size'] = 12\n",
    "        config['CNN_filters_1'] = 6\n",
    "    \n",
    "    args = Arguments(0,1,1,model_name)\n",
    "    model_saved, transformCompose, config, file_properties_df, pathmap = setup(args,config=config)\n",
    "\n",
    "\n",
    "    dataloader=prepare_dataloader_from_array(x_data[:])\n",
    "\n",
    "    # model = MyModel()\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "\n",
    "    model_saved.fc1.register_forward_hook(get_activation('fc1'))\n",
    "    # x = torch.randn(1, 25)\n",
    "    # output = model(x)\n",
    "    # print(activation['fc2'])\n",
    "\n",
    "    # def single_file_inference(dataloader, config, model_saved):\n",
    "    outputs = []\n",
    "    activations=[]\n",
    "    for inputs, labels in dataloader['predict']:\n",
    "    #     print(labels)\n",
    "        del labels\n",
    "        inputs = inputs.float().to(config['device'])\n",
    "\n",
    "        output = model_saved(inputs)\n",
    "        output = output.to('cpu')\n",
    "        index = output.data.numpy()\n",
    "        outputs.append(index)\n",
    "        activations.append(activation['fc1'])\n",
    "    # outputs.append(index)\n",
    "    #     outputs = np.concatenate(outputs)\n",
    "    #     return outputs\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # outputs_list=[]\n",
    "    # for out in outputs:\n",
    "    #     out_str=[ f\"{x:.2f}\" for x in list(sigmoid(out[0]))]\n",
    "    #     outputs_list.append(out_str)\n",
    "\n",
    "    outputs_list=[]\n",
    "    outputs_full_list=[]\n",
    "    outputs_sigmoid_full_list=[]\n",
    "    for out in outputs:\n",
    "        out_str=[ f\"{x:.2f}\" for x in list(torch.sigmoid(torch.tensor(out[0])))]\n",
    "        out_strfull=[ f\"{x}\" for x in list((out[0]))]\n",
    "        out_str_sigmoid_full=[ f\"{x}\" for x in list(torch.sigmoid(torch.tensor(out[0])))]\n",
    "\n",
    "        outputs_list.append(out_str)\n",
    "        outputs_full_list.append(out_strfull)\n",
    "        outputs_sigmoid_full_list.append(out_str_sigmoid_full)\n",
    "\n",
    "#     activationsnp=[]\n",
    "#     for act in activations:\n",
    "#         act = act.to('cpu')\n",
    "#         act = act.data.numpy()\n",
    "#         activationsnp.append(act)\n",
    "\n",
    "#     activationsnp=np.array(activationsnp)\n",
    "\n",
    "\n",
    "    # audio_index,file_paths\n",
    "    # pathmap.out_csv_file_name\n",
    "    with open(pathmap.out_csv_file_name,'w') as f:\n",
    "        f.writelines('sample_id,file_path,part_index,timestamp,location_id,set_name,'+target_taxo_header+','+target_taxo_names_header+'\\n')\n",
    "        for i,label_vector in enumerate(multi_label_vector):\n",
    "            label_vector = [str(i) for i in label_vector]\n",
    "            label_vector=','.join(label_vector)\n",
    "            pred_vector = outputs_sigmoid_full_list[i]\n",
    "            t = timestamps[i].strftime('%Y-%m-%d_%H:%M:%S')\n",
    "            f.writelines(f'{i},{file_paths[i]},{audio_index[i]},{t},{location_id_info[i]},{set_names[i]},{(label_vector)},'+(','.join(pred_vector))+'\\n')\n",
    "\n",
    "    asd=pd.read_csv(pathmap.out_csv_file_name)\n",
    "    preds=[i for i in asd.columns if 'pred' in i]\n",
    "    actual=[i.split('_')[0] for i in preds ]\n",
    "    valid=asd[asd['set_name']=='valid']\n",
    "    VALID_KK=roc_auc_perClass_compute_fn(np.array(valid[preds]),np.array(valid[actual]))\n",
    "\n",
    "    valid=asd[asd['set_name']=='test']\n",
    "    TEST_KK=roc_auc_perClass_compute_fn(np.array(valid[preds]),np.array(valid[actual]))\n",
    "    \n",
    "    print(pathmap.out_csv_file_name)\n",
    "    print(TEST_KK)\n",
    "    print(VALID_KK)\n",
    "    res_res.append([pathmap.out_csv_file_name,TEST_KK,VALID_KK])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out_str_sigmoid_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_20_min_ROC_AUC=0.7202.pt_labels_v0.csv'"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathmap.out_csv_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name      Age\n",
      "------  -----\n",
      "Alice      24\n",
      "Bob        19\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "print(tabulate([['Alice', 24], ['Bob', 19]], headers=['Name', 'Age']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict={}\n",
    "table_list=[]\n",
    "test_list=[]\n",
    "valid_list=[]\n",
    "i=0\n",
    "for name,test,valid in res_res:\n",
    "    short_name=name.split('/')[-1]\n",
    "    short_name=short_name.split('_')\n",
    "    short_name = short_name[1]+'_epoch-'+short_name[4]\n",
    "#     print(short_name)\n",
    "    table_list.append(('valid_'+short_name,*valid))\n",
    "    table_list.append(('test_'+short_name,*test))\n",
    "    test_list.append((short_name,*test))\n",
    "    valid_list.append((short_name,*valid))\n",
    "    \n",
    "    i+=2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n",
      "valid_dandy-sweep-196_epoch-68       0.712079  0.708273  0.706325  0.78401   0.814524  0.921007  0.744792  0.748295  0.726735\n",
      "test_dandy-sweep-196_epoch-68        0.699286  0.681486  0.350011  0.751324  0.831858  0.62086   0.706834  0.881923  0.735294\n",
      "valid_dandy-sweep-196_epoch-67       0.715728  0.70795   0.706158  0.772538  0.813865  0.922743  0.75      0.76461   0.71831\n",
      "test_dandy-sweep-196_epoch-67        0.708333  0.685437  0.355081  0.744743  0.833574  0.657706  0.722893  0.883918  0.727273\n",
      "valid_deep-sweep-198_epoch-12        0.713864  0.793598  0.729059  0.700015  0.738056  0.806134  0.707755  0.738149  0.706992\n",
      "test_deep-sweep-198_epoch-12         0.607974  0.654411  0.46175   0.699961  0.752228  0.645305  0.619445  0.831058  0.772646\n",
      "valid_deep-sweep-198_epoch-14        0.722249  0.791489  0.719832  0.698184  0.782936  0.836516  0.7011    0.729302  0.711896\n",
      "test_deep-sweep-198_epoch-14         0.622251  0.666988  0.461309  0.689486  0.767371  0.667599  0.642537  0.834384  0.774834\n",
      "valid_fearless-sweep-206_epoch-64    0.669377  0.708758  0.69552   0.784442  0.802316  0.826968  0.783565  0.807224  0.750755\n",
      "test_fearless-sweep-206_epoch-64     0.712895  0.71533   0.344014  0.717523  0.854528  0.730323  0.697498  0.905797  0.773132\n",
      "valid_fearless-sweep-206_epoch-66    0.670419  0.707798  0.69748   0.787062  0.806627  0.825231  0.782407  0.809091  0.753773\n",
      "test_fearless-sweep-206_epoch-66     0.71133   0.715527  0.346728  0.717056  0.854739  0.726093  0.698618  0.907197  0.772403\n",
      "valid_sweepy-sweep-203_epoch-36      0.696706  0.748091  0.714919  0.87556   0.824296  0.924769  0.709201  0.879545  0.702465\n",
      "test_sweepy-sweep-203_epoch-36       0.733366  0.717046  0.410478  0.795678  0.884875  0.606667  0.57382   0.867955  0.791201\n",
      "valid_sweepy-sweep-203_epoch-37      0.688831  0.741755  0.715146  0.882758  0.809884  0.936632  0.744792  0.873377  0.703597\n",
      "test_sweepy-sweep-203_epoch-37       0.741831  0.71972   0.404229  0.800662  0.881714  0.615914  0.574194  0.863439  0.790066\n",
      "valid_visionary-sweep-121_epoch-145  0.761269  0.711066  0.707736  0.811482  0.861477  0.721354  0.755787  0.817208  0.69668\n",
      "test_visionary-sweep-121_epoch-145   0.671076  0.711613  0.425784  0.756036  0.817076  0.597133  0.68978   0.807463  0.707665\n",
      "valid_visionary-sweep-121_epoch-148  0.761513  0.711151  0.706827  0.81222   0.862892  0.720486  0.755498  0.817695  0.69756\n",
      "test_visionary-sweep-121_epoch-148   0.66743   0.710086  0.426752  0.756503  0.815872  0.594194  0.690278  0.806238  0.708151\n",
      "valid_warm-sweep-160_epoch-10        0.713731  0.710125  0.725748  0.863731  0.831929  0.86169   0.743924  0.706494  0.720951\n",
      "test_warm-sweep-160_epoch-10         0.694343  0.654857  0.357648  0.825974  0.646195  0.608746  0.558571  0.857313  0.71755\n",
      "valid_warm-sweep-160_epoch-11        0.705324  0.707333  0.725916  0.867242  0.823572  0.883681  0.739583  0.713799  0.723089\n",
      "test_warm-sweep-160_epoch-11         0.70527   0.673379  0.360467  0.824961  0.656822  0.616272  0.568779  0.859308  0.744288\n",
      "valid_comic-sweep-29_epoch-20        0.725643  0.751254  0.723035  0.816265  0.808009  0.911748  0.720197  0.818182  0.756791\n",
      "test_comic-sweep-29_epoch-20         0.692176  0.6844    0.35647   0.686799  0.801752  0.624946  0.620627  0.587307  0.694296\n",
      "valid_comic-sweep-29_epoch-24        0.745209  0.754502  0.718756  0.837658  0.8189    0.90191   0.725984  0.816315  0.783702\n",
      "test_comic-sweep-29_epoch-24         0.652705  0.617572  0.366295  0.708022  0.729618  0.598996  0.673596  0.516208  0.674526\n",
      "-----------------------------------  --------  --------  --------  --------  --------  --------  --------  --------  --------\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(table_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(test) model_name                biophony      bird    songbirds    duck-goose-swan    anthrophony    insect    grouse-ptarmigan    aircraft    silence\n",
      "-----------------------------  ----------  --------  -----------  -----------------  -------------  --------  ------------------  ----------  ---------\n",
      "dandy-sweep-196_epoch-68         0.699286  0.681486     0.350011           0.751324       0.831858  0.62086             0.706834    0.881923   0.735294\n",
      "dandy-sweep-196_epoch-67         0.708333  0.685437     0.355081           0.744743       0.833574  0.657706            0.722893    0.883918   0.727273\n",
      "deep-sweep-198_epoch-12          0.607974  0.654411     0.46175            0.699961       0.752228  0.645305            0.619445    0.831058   0.772646\n",
      "deep-sweep-198_epoch-14          0.622251  0.666988     0.461309           0.689486       0.767371  0.667599            0.642537    0.834384   0.774834\n",
      "fearless-sweep-206_epoch-64      0.712895  0.71533      0.344014           0.717523       0.854528  0.730323            0.697498    0.905797   0.773132\n",
      "fearless-sweep-206_epoch-66      0.71133   0.715527     0.346728           0.717056       0.854739  0.726093            0.698618    0.907197   0.772403\n",
      "sweepy-sweep-203_epoch-36        0.733366  0.717046     0.410478           0.795678       0.884875  0.606667            0.57382     0.867955   0.791201\n",
      "sweepy-sweep-203_epoch-37        0.741831  0.71972      0.404229           0.800662       0.881714  0.615914            0.574194    0.863439   0.790066\n",
      "visionary-sweep-121_epoch-145    0.671076  0.711613     0.425784           0.756036       0.817076  0.597133            0.68978     0.807463   0.707665\n",
      "visionary-sweep-121_epoch-148    0.66743   0.710086     0.426752           0.756503       0.815872  0.594194            0.690278    0.806238   0.708151\n",
      "warm-sweep-160_epoch-10          0.694343  0.654857     0.357648           0.825974       0.646195  0.608746            0.558571    0.857313   0.71755\n",
      "warm-sweep-160_epoch-11          0.70527   0.673379     0.360467           0.824961       0.656822  0.616272            0.568779    0.859308   0.744288\n",
      "comic-sweep-29_epoch-20          0.692176  0.6844       0.35647            0.686799       0.801752  0.624946            0.620627    0.587307   0.694296\n",
      "comic-sweep-29_epoch-24          0.652705  0.617572     0.366295           0.708022       0.729618  0.598996            0.673596    0.516208   0.674526\n"
     ]
    }
   ],
   "source": [
    "headers = ['(test) model_name']+target_taxo_names\n",
    "print(tabulate(test_list,headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(valid) model_name               biophony      bird    songbirds    duck-goose-swan    anthrophony    insect    grouse-ptarmigan    aircraft    silence\n",
      "-----------------------------  ----------  --------  -----------  -----------------  -------------  --------  ------------------  ----------  ---------\n",
      "dandy-sweep-196_epoch-68         0.712079  0.708273     0.706325           0.78401        0.814524  0.921007            0.744792    0.748295   0.726735\n",
      "dandy-sweep-196_epoch-67         0.715728  0.70795      0.706158           0.772538       0.813865  0.922743            0.75        0.76461    0.71831\n",
      "deep-sweep-198_epoch-12          0.713864  0.793598     0.729059           0.700015       0.738056  0.806134            0.707755    0.738149   0.706992\n",
      "deep-sweep-198_epoch-14          0.722249  0.791489     0.719832           0.698184       0.782936  0.836516            0.7011      0.729302   0.711896\n",
      "fearless-sweep-206_epoch-64      0.669377  0.708758     0.69552            0.784442       0.802316  0.826968            0.783565    0.807224   0.750755\n",
      "fearless-sweep-206_epoch-66      0.670419  0.707798     0.69748            0.787062       0.806627  0.825231            0.782407    0.809091   0.753773\n",
      "sweepy-sweep-203_epoch-36        0.696706  0.748091     0.714919           0.87556        0.824296  0.924769            0.709201    0.879545   0.702465\n",
      "sweepy-sweep-203_epoch-37        0.688831  0.741755     0.715146           0.882758       0.809884  0.936632            0.744792    0.873377   0.703597\n",
      "visionary-sweep-121_epoch-145    0.761269  0.711066     0.707736           0.811482       0.861477  0.721354            0.755787    0.817208   0.69668\n",
      "visionary-sweep-121_epoch-148    0.761513  0.711151     0.706827           0.81222        0.862892  0.720486            0.755498    0.817695   0.69756\n",
      "warm-sweep-160_epoch-10          0.713731  0.710125     0.725748           0.863731       0.831929  0.86169             0.743924    0.706494   0.720951\n",
      "warm-sweep-160_epoch-11          0.705324  0.707333     0.725916           0.867242       0.823572  0.883681            0.739583    0.713799   0.723089\n",
      "comic-sweep-29_epoch-20          0.725643  0.751254     0.723035           0.816265       0.808009  0.911748            0.720197    0.818182   0.756791\n",
      "comic-sweep-29_epoch-24          0.745209  0.754502     0.718756           0.837658       0.8189    0.90191             0.725984    0.816315   0.783702\n"
     ]
    }
   ],
   "source": [
    "headers = ['(valid) model_name']+target_taxo_names\n",
    "print(tabulate(valid_list,headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_activations-fc1_v3.npy', 'wb') as f:\n",
    "#     np.save(f,activationsnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "biophony:0.75\n",
      "bird:0.75\n",
      "songbirds:0.72\n",
      "duck-goose-swan:0.84\n",
      "anthrophony:0.82\n",
      "insect:0.90\n",
      "grouse-ptarmigan:0.73\n",
      "aircraft:0.82\n",
      "silence:0.78\n"
     ]
    }
   ],
   "source": [
    "for h,i in zip(headers[1:],valid_list[-1][1:]):\n",
    "    print(f'{h}:{i:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(valid) model_name      biophony    bird    songbirds    duck-goose-swan    anthrophony    insect    grouse-ptarmigan    aircraft    silence\n",
      "--------------------  ----------  ------  -----------  -----------------  -------------  --------  ------------------  ----------  ---------\n",
      "none                        0.75    0.75         0.72               0.84           0.82       0.9                0.73        0.82       0.78\n"
     ]
    }
   ],
   "source": [
    "print(tabulate([['none']+[f'{i:.2f}' for i in valid_list[-1][1:]]],headers=headers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "(valid) model_name               biophony      bird    songbirds    duck-goose-swan    anthrophony    insect    grouse-ptarmigan    aircraft    silence\n",
    "-----------------------------  ----------  --------  -----------  -----------------  -------------  --------  ------------------  ----------  ---------\n",
    "dandy-sweep-196_epoch-68         0.712079  0.708273     0.706325           0.78401        0.814524  0.921007            0.744792    0.748295   0.726735\n",
    "dandy-sweep-196_epoch-67         0.715728  0.70795      0.706158           0.772538       0.813865  0.922743            0.75        0.76461    0.71831\n",
    "deep-sweep-198_epoch-12          0.713864  0.793598     0.729059           0.700015       0.738056  0.806134            0.707755    0.738149   0.706992\n",
    "# deep-sweep-198_epoch-14          0.722249  0.791489     0.719832           0.698184       0.782936  0.836516            0.7011      0.729302   0.711896\n",
    "fearless-sweep-206_epoch-64      0.669377  0.708758     0.69552            0.784442       0.802316  0.826968            0.783565    0.807224   0.750755\n",
    "# fearless-sweep-206_epoch-66      0.670419  0.707798     0.69748            0.787062       0.806627  0.825231            0.782407    0.809091   0.753773\n",
    "sweepy-sweep-203_epoch-36        0.696706  0.748091     0.714919           0.87556        0.824296  0.924769            0.709201    0.879545   0.702465\n",
    "# sweepy-sweep-203_epoch-37        0.688831  0.741755     0.715146           0.882758       0.809884  0.936632            0.744792    0.873377   0.703597\n",
    "# visionary-sweep-121_epoch-145    0.761269  0.711066     0.707736           0.811482       0.861477  0.721354            0.755787    0.817208   0.69668\n",
    "visionary-sweep-121_epoch-148    0.761513  0.711151     0.706827           0.81222        0.862892  0.720486            0.755498    0.817695   0.69756\n",
    "warm-sweep-160_epoch-10          0.713731  0.710125     0.725748           0.863731       0.831929  0.86169             0.743924    0.706494   0.720951\n",
    "warm-sweep-160_epoch-11          0.705324  0.707333     0.725916           0.867242       0.823572  0.883681            0.739583    0.713799   0.723089\n",
    "comic-sweep-29_epoch-20          0.725643  0.751254     0.723035           0.816265       0.808009  0.911748            0.720197    0.818182   0.756791\n",
    "comic-sweep-29_epoch-24          0.745209  0.754502     0.718756           0.837658       0.8189    0.90191             0.725984    0.816315   0.783702\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "comic-sweep-29_epoch-24         comic      deep        comic                sweepy        visionary    sweepy           fearless    sweepy     fearless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'comic-sweep-29_epoch-20 ',\n",
       " 'deep-sweep-198_epoch-14',\n",
       " 'fearless-sweep-206_epoch-66',\n",
       " 'sweepy-sweep-203_epoch-37',\n",
       " 'visionary-sweep-121_epoch-145'}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set({'biophony':'visionary-sweep-121_epoch-145',\n",
    "'bird':'deep-sweep-198_epoch-14',\n",
    "'songbirds':'comic-sweep-29_epoch-20 ',\n",
    "'duck-goose-swan':'sweepy-sweep-203_epoch-37',\n",
    "'anthrophony':'visionary-sweep-121_epoch-145',\n",
    "'insect':'sweepy-sweep-203_epoch-37',\n",
    "'grouse-ptarmigan':'fearless-sweep-206_epoch-66',\n",
    "'aircraft':'sweepy-sweep-203_epoch-37',\n",
    "'silence':'fearless-sweep-206_epoch-66'}.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(valid) model_name      biophony    bird    songbirds    duck-goose-swan    anthrophony    insect    grouse-ptarmigan    aircraft    silence\n",
    "--------------------  ----------  ------  -----------  -----------------  -------------  --------  ------------------  ----------  ---------\n",
    "none                        0.75    0.79         0.72               0.88           0.86       0.9                0.78        0.87       0.78\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'deep-sweep-198/best_model_14_min_ROC_AUC=0.6982.pt',\n",
    "elif 'deep-sweep-198' in model_name:\n",
    "    config['CNN_filters_1'] = 5\n",
    "    config['CNN_kernel_size'] = 12\n",
    "    config['fc_1_size'] = 84\n",
    "\n",
    "'fearless-sweep-206/best_model_64_min_ROC_AUC=0.6955.pt',\n",
    "\n",
    "elif 'fearless-sweep-206' in model_name:\n",
    "    config['CNN_filters_1'] = 5\n",
    "    config['CNN_kernel_size'] = 12\n",
    "    config['fc_1_size'] = 115\n",
    "        \n",
    "'sweepy-sweep-203/best_model_37_min_ROC_AUC=0.7036.pt'\n",
    "\n",
    "elif 'sweepy-sweep-203' in model_name:\n",
    "    config['CNN_filters_1'] = 12\n",
    "    config['CNN_kernel_size'] = 12\n",
    "    config['fc_1_size'] = 87\n",
    "        \n",
    "'visionary-sweep-121/best_model_145_min_ROC_AUC=0.6967.pt',\n",
    "\n",
    "elif 'visionary-sweep-121' in model_name:\n",
    "    config['CNN_filters_1'] = 4\n",
    "    config['CNN_kernel_size'] = 12\n",
    "    config['fc_1_size'] = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 0, 0, 0, 0, 0, 0, 0, 0], 'valid')"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_label_vector[0],set_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('biophony_pred,bird_pred,songbirds_pred,duck-goose-swan_pred,anthrophony_pred,insect_pred,grouse-ptarmigan_pred,aircraft_pred,silence_pred',\n",
       " 'biophony,bird,songbirds,duck-goose-swan,anthrophony,insect,grouse-ptarmigan,aircraft,silence')"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_taxo_names_header,target_taxo_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_index,file_paths\n",
    "# with open('/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_activations-fc1_labels_v2.csv','w') as f:\n",
    "#     f.writelines('sample_id,file_path,part_index,set_name,location_id,timestamp,'+(','.join(target_taxo))+'\\n')\n",
    "#     for i,label_vector in enumerate(multi_label_vector):\n",
    "#         label_vector = [str(i) for i in label_vector]\n",
    "#         t = timestamps[i].strftime('%Y-%m-%d_%H:%M:%S')\n",
    "#         f.writelines(f'{i},{file_paths[i]},{audio_index[i]},{t},{location_id_info[i]},{set_names[i]},'+(','.join(label_vector))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs_sigmoid_full_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_index,file_paths\n",
    "# pathmap.out_csv_file_name\n",
    "with open('test20.csv','w') as f:\n",
    "    f.writelines('sample_id,file_path,part_index,timestamp,location_id,set_name,'+target_taxo_header+','+target_taxo_names_header+'\\n')\n",
    "    for i,label_vector in enumerate(multi_label_vector):\n",
    "        label_vector = [str(i) for i in label_vector]\n",
    "        label_vector=','.join(label_vector)\n",
    "        pred_vector = outputs_full_list[i]\n",
    "        t = timestamps[i].strftime('%Y-%m-%d_%H:%M:%S')\n",
    "        f.writelines(f'{i},{file_paths[i]},{audio_index[i]},{t},{location_id_info[i]},{set_names[i]},{(label_vector)},'+(','.join(pred_vector))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_index,file_paths\n",
    "# pathmap.out_csv_file_name\n",
    "with open('testsigmoidfull.csv','w') as f:\n",
    "    f.writelines('sample_id,file_path,part_index,timestamp,location_id,set_name,'+target_taxo_header+','+target_taxo_names_header+'\\n')\n",
    "    for i,label_vector in enumerate(multi_label_vector):\n",
    "        label_vector = [str(i) for i in label_vector]\n",
    "        label_vector=','.join(label_vector)\n",
    "        pred_vector = outputs_sigmoid_full_list[i]\n",
    "        t = timestamps[i].strftime('%Y-%m-%d_%H:%M:%S')\n",
    "        f.writelines(f'{i},{file_paths[i]},{audio_index[i]},{t},{location_id_info[i]},{set_names[i]},{(label_vector)},'+(','.join(pred_vector))+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def roc_auc_perClass_compute_fn(y_pred, y_true):\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "    except ImportError:\n",
    "        raise RuntimeError(\n",
    "            \"This contrib module requires sklearn to be installed.\")\n",
    "\n",
    "    res = roc_auc_score(y_true, y_pred, average=None)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biophony',\n",
       " 'bird',\n",
       " 'songbirds',\n",
       " 'duck-goose-swan',\n",
       " 'anthrophony',\n",
       " 'insect',\n",
       " 'grouse-ptarmigan',\n",
       " 'aircraft',\n",
       " 'silence']"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid[actual]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid[preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_np=np.array(valid[preds])\n",
    "y_true_np=np.array(valid[actual])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.6819e-01, 3.7327e-02, 2.4049e-01,  ..., 2.5477e-03, 2.3661e-02,\n",
       "         1.7612e-03],\n",
       "        [9.4931e-01, 6.1203e-03, 8.9244e-03,  ..., 6.3579e-04, 1.3674e-05,\n",
       "         4.6176e-04],\n",
       "        [2.4601e-01, 2.5831e-02, 4.1824e-01,  ..., 2.2603e-03, 6.7597e-03,\n",
       "         1.0478e-03],\n",
       "        ...,\n",
       "        [9.9844e-01, 9.4532e-01, 2.4787e-01,  ..., 1.2026e-01, 4.9933e-07,\n",
       "         5.1074e-08],\n",
       "        [9.9811e-01, 9.7516e-01, 9.5391e-01,  ..., 3.1269e-04, 2.7262e-05,\n",
       "         1.1367e-07],\n",
       "        [9.9508e-01, 9.9081e-01, 4.5017e-01,  ..., 3.8573e-04, 1.6621e-07,\n",
       "         2.9829e-05]], dtype=torch.float64)"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.tensor(np.array(valid[preds])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Biophony: 0.6342\n",
    "Bird: 0.7459\n",
    "Songbirds: 0.7204\n",
    "Duck.goose.swan: 0.773\n",
    "Anthrophony: 0.5855\n",
    "Insect: 0.9115\n",
    "Grouse.Ptarmigan: 0.7771\n",
    "Aircraft: 0.526\n",
    "Silence: 0.4974"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_comic-sweep-29_epoch-20        0.725643  0.751254  0.723035  0.816265  0.808009  0.911748  0.720197  0.818182  0.756791\n",
    "test_comic-sweep-29_epoch-20         0.692176  0.6844    0.35647   0.686799  0.801752  0.624946  0.620627  0.587307  0.694296\n",
    "valid_comic-sweep-29_epoch-24        0.745209  0.754502  0.718756  0.837658  0.8189    0.90191   0.725984  0.816315  0.783702\n",
    "test_comic-sweep-29_epoch-24         0.652705  0.617572  0.366295  0.708022  0.729618  0.598996  0.673596  0.516208  0.674526"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_24_min_ROC_AUC=0.7188.pt_labels_v0.csv\n",
      "[0.74554126 0.75450228 0.71874402 0.83781034 0.81888326 0.90190972\n",
      " 0.73133681 0.81635552 0.78420523]\n"
     ]
    }
   ],
   "source": [
    "with open('test_pre.csv','w') as f:\n",
    "    f.writelines('sample_id,file_path,part_index,timestamp,location_id,set_name,'+target_taxo_header+','+target_taxo_names_header+'\\n')\n",
    "    for i,label_vector in enumerate(multi_label_vector):\n",
    "        label_vector = [str(i) for i in label_vector]\n",
    "        label_vector=','.join(label_vector)\n",
    "        pred_vector = [f'{float(i):.6f}' for i in outputs_sigmoid_full_list[i]]\n",
    "        t = timestamps[i].strftime('%Y-%m-%d_%H:%M:%S')\n",
    "        f.writelines(f'{i},{file_paths[i]},{audio_index[i]},{t},{location_id_info[i]},{set_names[i]},{(label_vector)},'+(','.join(pred_vector))+'\\n')\n",
    "\n",
    "    \n",
    "asd=pd.read_csv('test_pre.csv')\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(np.array(valid[preds]),np.array(valid[actual]))\n",
    "print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.6690313816070557',\n",
       " '0.037341345101594925',\n",
       " '0.2412663996219635',\n",
       " '0.017971660941839218',\n",
       " '0.8155879378318787',\n",
       " '0.47860562801361084',\n",
       " '0.002548219170421362',\n",
       " '0.02363586612045765',\n",
       " '0.0017552142962813377']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_sigmoid_full_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i,label_vector in enumerate(multi_label_vector):\n",
    "#     for i in outputs_sigmoid_full_list[i]:\n",
    "#         if 'e' in i:\n",
    "#             print(i)\n",
    "# #     pred_vector = [i[:] for i in outputs_sigmoid_full_list[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63421695 0.74593465 0.72039348 0.77295737 0.58545012 0.91145833\n",
      " 0.7770544  0.52597403 0.49735915]\n"
     ]
    }
   ],
   "source": [
    "shared='/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_activations-fc1_labels_v4.csv'\n",
    "asd=pd.read_csv(shared)\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(np.array(valid[preds]),np.array(valid[actual]))\n",
    "# print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63421695 0.74593465 0.72039348 0.77295737 0.58545012 0.91145833\n",
      " 0.7770544  0.52597403 0.49735915]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "shared='/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_activations-fc1_labels_v4.csv'\n",
    "asd=pd.read_csv(shared)\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(torch.sigmoid(torch.tensor(np.array(valid[preds]))),np.array(valid[actual]))\n",
    "# print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_20_min_ROC_AUC=0.7202.pt_labels_v0.csv\n",
      "[0.7256433  0.7512538  0.723035   0.81626475 0.80800869 0.91174769\n",
      " 0.72019676 0.81818182 0.75679074]\n"
     ]
    }
   ],
   "source": [
    "asd=pd.read_csv('testsigmoidfull.csv')\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(np.array(valid[preds]),np.array(valid[actual]))\n",
    "print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_24_min_ROC_AUC=0.7188.pt_labels_v0.csv\n",
      "[0.74524179 0.75451178 0.71875598 0.83760684 0.81886681 0.90190972\n",
      " 0.72583912 0.81627435 0.78351358]\n"
     ]
    }
   ],
   "source": [
    "asd=pd.read_csv('test.csv')\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(torch.sigmoid(torch.tensor(np.array(valid[preds]))),np.array(valid[actual]))\n",
    "print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_comic-sweep-29_best_model_24_min_ROC_AUC=0.7188.pt_labels_v0.csv\n",
      "[0.74524179 0.75451178 0.71875598 0.83760684 0.81886681 0.90190972\n",
      " 0.72583912 0.81627435 0.78351358]\n"
     ]
    }
   ],
   "source": [
    "asd=pd.read_csv('test.csv')\n",
    "preds=[i for i in asd.columns if 'pred' in i]\n",
    "actual=[i.split('_')[0] for i in preds ]\n",
    "valid=asd[asd['set_name']=='valid']\n",
    "kk=roc_auc_perClass_compute_fn(sigmoid(np.array(valid[preds])),np.array(valid[actual]))\n",
    "print(pathmap.out_csv_file_name)\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.95'"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{sigmoid(np.array(valid[preds]))[1][0]:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9493096750687493"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array(valid[preds]))[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_warm-sweep-160_best_model_11_min_ROC_AUC=0.7076.pt_labels_v0.csv\n",
    "# [0.63068988 0.68847834 0.70840505 0.83750509 0.81001579 0.83695023\n",
    "#  0.74117477 0.4875     0.49823944]\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_warm-sweep-160_best_model_10_min_ROC_AUC=0.7065.pt_labels_v0.csv\n",
    "# [0.656189   0.69231573 0.7028232  0.84581044 0.82189392 0.75245949\n",
    "#  0.81163194 0.49375    0.49911972]\n",
    "\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_visionary-sweep-121_best_model_148_min_ROC_AUC=0.6976.pt_labels_v0.csv\n",
    "# [0.56852263 0.66474164 0.69940476 0.68620269 0.51625428 0.5240162\n",
    "#  0.47569444 0.5        0.49647887]\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_visionary-sweep-121_best_model_145_min_ROC_AUC=0.6967.pt_labels_v0.csv\n",
    "# [0.57481145 0.66358283 0.68593421 0.68615181 0.51533298 0.52546296\n",
    "#  0.47569444 0.5        0.49647887]\n",
    "\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_sweepy-sweep-203_best_model_37_min_ROC_AUC=0.7036.pt_labels_v0.csv\n",
    "# [0.50706522 0.67740312 0.70496271 0.7847095  0.4971374  0.88845486\n",
    "#  0.49045139 0.5        0.49735915]\n",
    "\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_sweepy-sweep-203_best_model_36_min_ROC_AUC=0.7025.pt_labels_v0.csv\n",
    "# [0.50174135 0.69028305 0.70960031 0.78414988 0.50478744 0.87731481\n",
    "#  0.49045139 0.5        0.49735915]\n",
    "\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_fearless-sweep-206_best_model_66_min_ROC_AUC=0.6975.pt_labels_v0.csv\n",
    "# [0.49081633 0.6875     0.64633534 0.69288004 0.58207752 0.63686343\n",
    "#  0.80801505 0.49285714 0.49823944]\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_deep-sweep-198_best_model_14_min_ROC_AUC=0.6982.pt_labels_v0.csv\n",
    "# [0.71947649 0.78992211 0.7176922  0.69301994 0.78285404 0.83969907\n",
    "#  0.7572338  0.65105519 0.59400151]\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_deep-sweep-198_best_model_12_min_ROC_AUC=0.7000.pt_labels_v0.csv\n",
    "# [0.71315439 0.79289514 0.72886785 0.69170991 0.73715122 0.79427083\n",
    "#  0.75911458 0.63348214 0.59557344]\n",
    "\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_dandy-sweep-196_best_model_67_min_ROC_AUC=0.7062.pt_labels_v0.csv\n",
    "# [0.48979592 0.69020707 0.68544416 0.67560796 0.66800474 0.80063657\n",
    "#  0.62934028 0.49732143 0.49823944]\n",
    "\n",
    "# /scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite_post/run-5_dandy-sweep-196_best_model_68_min_ROC_AUC=0.7063.pt_labels_v0.csv\n",
    "# [0.51574978 0.69265767 0.67760327 0.67920737 0.68733548 0.79239005\n",
    "#  0.64351852 0.49196429 0.49735915]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[0.71315439 0.79289514 0.72886785 0.84581044 0.78285404 0.88845486 \n",
    "0.81163194 0.65105519  0.49735915]\n",
    "['biophony',\n",
    " 'bird', ok\n",
    " 'songbirds',\n",
    " 'duck-goose-swan', ok\n",
    " 'anthrophony', ook\n",
    " 'insect', ok \n",
    " 'grouse-ptarmigan', ok\n",
    " 'aircraft',\n",
    " 'silence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nna.exp.megan import preparedataset\n",
    "# preparedataset.load_taxonomy2dataset(('/home/enis/projects/nna/src/nna/assets/taxonomy/taxonomy.yaml'), audio_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biophony'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_dataset.update_samples_w_clipping_info(\n",
    "#     output_folder=pathmap.clipping_results_path)\n",
    "# # print('inference part')\n",
    "# for audio_ins in audio_dataset.values():\n",
    "# #     if is_result_exist(audio_ins, label_names, v_str,\n",
    "# #                        file_properties_df, pathmap):\n",
    "# #         continue\n",
    "#     dataloader = prepare_dataloader_from_audio_ins(\n",
    "#         audio_ins, config, transformCompose)\n",
    "#     outputs = single_file_inference(dataloader, config, model_saved)\n",
    "#     break\n",
    "    \n",
    "# #     save_results_disk(outputs, audio_ins, label_names, v_str,\n",
    "# #                       file_properties_df, pathmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_location_datasets = load_audio_files(region_location,\n",
    "                                            file_properties_df)\n",
    "label_names = config['label_names']\n",
    "v_str = config['v_str']\n",
    "# for region, location in region_location:\n",
    "#     print(region, location)\n",
    "#     region_location_ins = region_location_datasets[(region, location)]\n",
    "    region_location_ins.update_samples_w_clipping_info(\n",
    "        output_folder=pathmap.clipping_results_path)\n",
    "    # print('inference part')\n",
    "    for audio_ins in region_location_ins.values():\n",
    "        if is_result_exist(audio_ins, label_names, v_str,\n",
    "                           file_properties_df, pathmap):\n",
    "            continue\n",
    "        dataloader = prepare_dataloader_from_audio_ins(\n",
    "            audio_ins, config, transformCompose)\n",
    "        outputs = single_file_inference(dataloader, config, model_saved)\n",
    "        save_results_disk(outputs, audio_ins, label_names, v_str,\n",
    "                          file_properties_df, pathmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another thing\n",
    "# with open('/scratch/enis/data/nna/labeling/megan/AudioSamplesPerSite/files_filtered_v3_info.csv','w') as f:\n",
    "#     f.writelines(f'file_name,taxo_code,location_id\\n')\n",
    "#     for file_name in cached_dict.keys():\n",
    "# #         print(file_name)\n",
    "#         audio=audio_dataset[file_name.split('/')[-1]]\n",
    "#         taxo_code=audio.taxo_code\n",
    "#         location_id=audio.location_id\n",
    "        \n",
    "#         f.writelines(f'{file_name},{taxo_code},{location_id}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4166666666666667 0.4166666666666667\n"
     ]
    }
   ],
   "source": [
    "y_true=[1,1,1,1,0,0,0,0,1,1]\n",
    "y_pred=[1,-1,-221,1,2,3,-4,-2,1,1]\n",
    "y_pred_s=sigmoid(np.array(y_pred))\n",
    "\n",
    "ro=roc_auc_score(y_true, y_pred, average=None)\n",
    "ro_s = roc_auc_score(y_true, y_pred_s, average=None)\n",
    "print(ro,ro_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.7 ,  -3.25,  -1.15, ...,  -5.97,  -3.72,  -6.34],\n",
       "        [  2.93,  -5.09,  -4.71, ...,  -7.36, -11.2 ,  -7.68],\n",
       "        [ -1.12,  -3.63,  -0.33, ...,  -6.09,  -4.99,  -6.86],\n",
       "        ...,\n",
       "        [  6.46,   2.85,  -1.11, ...,  -1.99, -14.51, -16.79],\n",
       "        [  6.27,   3.67,   3.03, ...,  -8.07, -10.51, -15.99],\n",
       "        [  5.31,   4.68,  -0.2 , ...,  -7.86, -15.61, -10.42]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]]))"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np,y_true_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7452417923691216"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true_np[:,0], preds_np[:,0], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582,)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true_np[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7 ,  2.93, -1.12,  1.54, -0.03, -0.95,  1.61,  4.92,  5.97,\n",
       "        5.9 ])"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_np[:,0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66818777, 0.94930968, 0.24601128, 0.82346473, 0.49250056,\n",
       "       0.27888482, 0.83341139, 0.99275376, 0.99745227, 0.99726804])"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(preds_np[:,0])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2916666666666667, 0.2916666666666667)"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, sigmoid(preds_np[:,1])[:10], average=None),roc_auc_score(y_true, (preds_np[:,1])[:10], average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-418-5daa6df001e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid() missing 1 required positional arguments: \"input\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-428-299ba71c3a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid() missing 1 required positional arguments: \"input\""
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd='/scratch/enis/data/nna/database/allFields_dataV5.pkl'\n",
    "bcd=pd.read_pickle(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>locationId</th>\n",
       "      <th>site_name</th>\n",
       "      <th>recorderId</th>\n",
       "      <th>hour_min_sec</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>region</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationSec</th>\n",
       "      <th>timestampEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200812_160000.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>160000</td>\n",
       "      <td>2020</td>\n",
       "      <td>08</td>\n",
       "      <td>12</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-08-12 16:00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-08-12 16:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200916_052000.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>052000</td>\n",
       "      <td>2020</td>\n",
       "      <td>09</td>\n",
       "      <td>16</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-09-16 05:20:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-09-16 05:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200427_201234.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>201234</td>\n",
       "      <td>2020</td>\n",
       "      <td>04</td>\n",
       "      <td>27</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-04-27 20:12:34</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-04-27 20:17:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200916_184000.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>184000</td>\n",
       "      <td>2020</td>\n",
       "      <td>09</td>\n",
       "      <td>16</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-09-16 18:40:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-09-16 18:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200825_104000.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>104000</td>\n",
       "      <td>2020</td>\n",
       "      <td>08</td>\n",
       "      <td>25</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-08-25 10:40:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-08-25 10:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200429_025234.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>025234</td>\n",
       "      <td>2020</td>\n",
       "      <td>04</td>\n",
       "      <td>29</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-04-29 02:52:34</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-04-29 02:57:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200402_025234.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>025234</td>\n",
       "      <td>2020</td>\n",
       "      <td>04</td>\n",
       "      <td>02</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-04-02 02:52:34</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-04-02 02:57:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200525_145234.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>145234</td>\n",
       "      <td>2020</td>\n",
       "      <td>05</td>\n",
       "      <td>25</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-05-25 14:52:34</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-05-25 14:57:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20200523_121234.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>121234</td>\n",
       "      <td>2020</td>\n",
       "      <td>05</td>\n",
       "      <td>23</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-05-23 12:12:34</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-05-23 12:17:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/real/dempster/14/2020/S4A10424_20201019_040000.flac</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td></td>\n",
       "      <td>S4A10424</td>\n",
       "      <td>040000</td>\n",
       "      <td>2020</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>dempster</td>\n",
       "      <td>2020-10-19 04:00:00</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2020-10-19 04:05:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3207 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   site_id locationId  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "...                                                    ...        ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...      14         14   \n",
       "\n",
       "                                                   site_name recorderId  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "...                                                      ...        ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...             S4A10424   \n",
       "\n",
       "                                                   hour_min_sec  year month  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       160000  2020    08   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       052000  2020    09   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       201234  2020    04   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       184000  2020    09   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       104000  2020    08   \n",
       "...                                                         ...   ...   ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       025234  2020    04   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       025234  2020    04   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       145234  2020    05   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       121234  2020    05   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       040000  2020    10   \n",
       "\n",
       "                                                   day    region  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  12  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  16  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  27  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  16  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  25  dempster   \n",
       "...                                                 ..       ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  29  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  02  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  25  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  23  dempster   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...  19  dempster   \n",
       "\n",
       "                                                             timestamp  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-08-12 16:00:00   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-09-16 05:20:00   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-27 20:12:34   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-09-16 18:40:00   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-08-25 10:40:00   \n",
       "...                                                                ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-29 02:52:34   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-02 02:52:34   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-05-25 14:52:34   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-05-23 12:12:34   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-10-19 04:00:00   \n",
       "\n",
       "                                                   durationSec  \\\n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "...                                                        ...   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2...       300.0   \n",
       "\n",
       "                                                          timestampEnd  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-08-12 16:05:00  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-09-16 05:25:00  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-27 20:17:34  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-09-16 18:45:00  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-08-25 10:45:00  \n",
       "...                                                                ...  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-29 02:57:34  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-04-02 02:57:34  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-05-25 14:57:34  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-05-23 12:17:34  \n",
       "/tank/data/nna/real/dempster/14/2020/S4A10424_2... 2020-10-19 04:05:00  \n",
       "\n",
       "[3207 rows x 12 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk=bcd[bcd['year']=='2020']\n",
    "kk[kk['site_id']=='14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
