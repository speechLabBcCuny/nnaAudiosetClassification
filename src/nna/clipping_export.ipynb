{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''get list all files ending from a given folder  with Path module'''\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np \n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_all_files_from_folder(folder_path, file_extension):\n",
    "    \"\"\"get list all files ending from a given folder  with Path module\"\"\"\n",
    "    folder_path = Path(folder_path)\n",
    "    file_list = list(folder_path.glob(f'*.{file_extension}'))\n",
    "    return file_list\n",
    "\n",
    "def flatten_clipping_dict2csv_format(clipping_dict, file_properties_df,excerpt_duration=10):\n",
    "    \"\"\"flatten clipping array to csv format\n",
    "\n",
    "    \"\"\"\n",
    "    existing_files = set([str(file) for file in file_properties_df.index])\n",
    "\n",
    "    def get_file_row(file_path,existing_files):\n",
    "        \"\"\"get file row from file_properties_df\"\"\"\n",
    "        if file_path not in existing_files:\n",
    "            return None,None,None\n",
    "        file_row=file_properties_df.loc[Path(file_path)]\n",
    "        region  = file_row['region']\n",
    "        location = file_row['locationId']\n",
    "        timestamp = file_row['timestamp']\n",
    "        return region, location, timestamp\n",
    "\n",
    "    \n",
    "    def sort_files_by_timestamp(clipping_dict,existing_files):\n",
    "        \"\"\"sort files by timestamp to make sure we have the correct order\"\"\"\n",
    "        max_channel = 0\n",
    "        clipping_files_per_location = []\n",
    "        for file_path,clipping in clipping_dict.items():\n",
    "            max_channel = max(max_channel,clipping.shape[1])\n",
    "            region, location, timestamp = get_file_row(file_path,existing_files)\n",
    "            if timestamp is None:\n",
    "                continue\n",
    "            clipping_files_per_location.append((file_path,region,location,timestamp,max_channel))\n",
    "            # sort by timestamp\n",
    "            clipping_files_per_location.sort(key=lambda x: x[3])\n",
    "        return clipping_files_per_location, max_channel\n",
    "    \n",
    "    clipping_files_per_location, max_channel = sort_files_by_timestamp(clipping_dict,existing_files)\n",
    "\n",
    "    csv_list = []\n",
    "    for file_info in clipping_files_per_location:\n",
    "        file_path,region,location,timestamp,max_channel = file_info\n",
    "        clipping = clipping_dict[file_path]\n",
    "\n",
    "        for clipping_values in clipping:\n",
    "            # format floats with four digits after the decimal point\n",
    "            clipping_values = [ f'{x:.4f}' for x in clipping_values]\n",
    "            timestamp_str = timestamp.strftime('%Y-%m-%d_%H:%M:%S')\n",
    "            csv_list.append((file_path.replace('/tank/data/nna/real/',''),timestamp_str,*clipping_values))\n",
    "            timestamp += pd.Timedelta(seconds=excerpt_duration)\n",
    "    return csv_list, max_channel\n",
    "\n",
    "\n",
    "def save_csv_file(csv_list, max_channel, file_path):\n",
    "    \"\"\"save csv file with csv library\"\"\"\n",
    "    with open(file_path, 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['file_path','timestamp']+['channel_'+str(i) for i in range(max_channel)])\n",
    "        csvwriter.writerows(csv_list)\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = Path('/scratch/enis/data/nna/clipping_info/csv_exports/all-merged_2022-09-12')\n",
    "INPUT_FOLDER = Path('/scratch/enis/data/nna/clipping_info/all-merged_2022-09-12')\n",
    "file_extension = 'pkl'\n",
    "clipping_files = get_all_files_from_folder(str(INPUT_FOLDER), file_extension)\n",
    "\n",
    "file_database = '/scratch/enis/data/nna/database/allFields_dataV102.pkl'\n",
    "file_properties_df = pd.read_pickle(file_database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/scratch/enis/data/nna/clipping_info/csv_exports/all-merged_2022-09-12')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OUTPUT_FOLDER\n",
    "\n",
    "# NEEED TO SORT THE FILES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OUTPUT_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for clipping_file in clipping_files:\n",
    "    clipping_info = np.load(str(clipping_file), allow_pickle=True)[()]\n",
    "    csv_file_per_loc,max_channel = flatten_clipping_dict2csv_format(clipping_info, file_properties_df,excerpt_duration=10)\n",
    "    file_path  = OUTPUT_FOLDER / f'{clipping_file.stem}.csv'\n",
    "    save_csv_file(csv_file_per_loc, max_channel,str(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('dalton/10/2019/S4A10350_20190318_122302.flac',\n",
       " '2019-03-18_12:23:02',\n",
       " '0.3806',\n",
       " '0.3211')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_per_loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
