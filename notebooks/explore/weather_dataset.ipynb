{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "133f7854-7bae-4f70-9080-005e3c1be00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c75d65d3314702ab25cb38f512c9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LOCAL=False\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "if LOCAL:\n",
    "    path = '/Users/berk/Documents/research/nna/src/scripts/'\n",
    "else:\n",
    "    path = '/home/enis/projects/nna/src/scripts/'\n",
    "os.chdir(path)\n",
    "\n",
    "import teacher\n",
    "from nna import weather\n",
    "\n",
    "# import itertools\n",
    "import pandas as pd\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebe5c77-30cb-47ac-a2ff-167e18cbdee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(teacher)\n",
    "importlib.reload(weather)\n",
    "\n",
    "version_tag='weather_V2'\n",
    "config = teacher.setup(versiontag=version_tag)\n",
    "\n",
    "weather_data_folder='/scratch/enis/data/nna/weather_data/2017_2020'\n",
    "# weather_data_folder='/Users/berk/Downloads/NNA_files/weather_data/2017_2020'\n",
    "root_path = '/scratch/enis/data/nna/labeling/samples'\n",
    "config['split_out_path'] = f'{root_path}/{version_tag}/audio_'\n",
    "\n",
    "## data-1: as many sampes as possible\n",
    "config['new_dataset_path'] = f'{root_path}/{version_tag}/{version_tag}.csv'\n",
    "config['dataset_version'] = 'W1'\n",
    "# config['versiontag'] = 'yfitloiq-V1'\n",
    "config['excell_label_headers']=['day_length','air_temp','snow_depth',\n",
    "        'cloud_fraction','relative_humidity','runoff','rain_precip',\n",
    "         'snow_precip','wind_direction','wind_speed']\n",
    "\n",
    "# config['excell_label_headers']=['day_length','air_temp','snow_depth',\n",
    "#         'cloud_fraction','relative_humidity','runoff','rain_precip',\n",
    "#          'snow_precip','wind_direction','wind_speed',\n",
    "#         'snow_blowing_ground','snow_blowing_air',]\n",
    "\n",
    "\n",
    "config['upper_taxo_links']={}\n",
    "\n",
    "FILE_PER_LOCATION=200\n",
    "# print('total sample count to be produced:',file_per_location*len(short_ones.keys()))\n",
    "\n",
    "# 40 Prudhoe or ANWR monitoring sites AND the Ivvavik sites\n",
    "short_input_csv_headers = ['day_length','air_temp','snow_depth',\n",
    "        'cloud_fraction','relative_humidity','runoff','rain_precip',\n",
    "         'snow_precip','wind_direction','wind_speed']\n",
    "# (year,month,day,hour,day_length,air_temp,snow_depth,\n",
    "#                 cloud_fraction,relative_humidity,runoff,rain_precip,\n",
    "#                     snow_precip,wind_direction,wind_speed)=row\n",
    "# for Dalton and Dempster\n",
    "long_input_csv_headers = ['day_length','air_temp','snow_depth',\n",
    "        'cloud_fraction','relative_humidity','runoff','rain_precip',\n",
    "         'snow_precip','total_precip','wind_direction','wind_speed',\n",
    "        'snow_blowing_ground','snow_blowing_air']\n",
    "\n",
    "\n",
    "# (year,month,day,hour,day_length,air_temp,snow_depth,\n",
    "# cloud_fraction,relative_humidity,runoff,rain_precip,\n",
    "# snow_precip,total_precip,wind_direction,wind_speed,\n",
    "# snow_blowing_ground,snow_blowing_air)=row\n",
    "\n",
    "short_locations=('prudhoe','ivvavik','anwr')\n",
    "long_locations=('dalton','dempster')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "781f0ef5-3e02-46f4-9abd-64dc85a125b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOCAL:\n",
    "    file_database = '/Users/berk/Documents/scratch/enis/data/nna/database/allFields_dataV10.pkl'\n",
    "else:\n",
    "    file_database = '/scratch/enis/data/nna/database/allFields_dataV10.pkl'\n",
    "file_properties_df = pd.read_pickle(file_database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e5a0b15-a123-4a56-9e9d-34214061332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_csv = weather.csv_path_per_regloc(weather_data_folder)\n",
    "station_years = weather.year_per_regloc(station_csv,file_properties_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc122ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge all data to see distributions\n",
    "dataframes=[]\n",
    "for (region,location),fname in station_csv.items():\n",
    "    print(region,location)\n",
    "    csv_reader,short = weather.load_rows(fname,region,short_locations,long_locations)\n",
    "    rows_picked = weather.get_random_rows(csv_reader,FILE_PER_LOCATION,station_years[(region,location)])\n",
    "\n",
    "    pd_rows = weather.parse_rows(rows_picked,location,region,short,short_input_csv_headers,long_input_csv_headers)\n",
    "\n",
    "\n",
    "    selected_data=pd.DataFrame(pd_rows)\n",
    "    dataframes.append(selected_data)\n",
    "\n",
    "# unmatching columns will be filled with NaN\n",
    "# ignore_index=True will create new index\n",
    "selected_data=pd.concat(dataframes,ignore_index=True)\n",
    "\n",
    "selected_data['rain_precip_mm'] = selected_data['rain_precip']*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ba09e52-4330-4fe0-9664-acc0850f25b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'station_years' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m (region,location),fname \u001b[39min\u001b[39;00m station_csv\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     csv_reader,short \u001b[39m=\u001b[39m load_rows(fname,region,short_locations,long_locations)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     rows_picked \u001b[39m=\u001b[39m get_random_rows(csv_reader,FILE_PER_LOCATION,station_years)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     pd_rows \u001b[39m=\u001b[39m parse_rows(rows_picked,location,region,short,short_input_csv_headers,long_input_csv_headers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/berk/Documents/research/nna/notebooks/explore/weather_dataset.ipynb#X12sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     selected_data\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(pd_rows)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'station_years' is not defined"
     ]
    }
   ],
   "source": [
    "new_dataset_csv, not_found_rows = teacher.generate_new_dataset(\n",
    "    selected_data,\n",
    "    config['versiontag'],\n",
    "    config['split_out_path'],\n",
    "    file_properties_df,\n",
    "    config['upper_taxo_links'],\n",
    "    config['dataset_version'],\n",
    "    buffer=3600,\n",
    "    excell_label_headers= {},#config['excell_label_headers'],\n",
    "    labels_thresholds= {},#config['labels_thresholds'],\n",
    "    outputSuffix='.wav',\n",
    "    dry_run=False,\n",
    "    excell_labels_2_names= {}, #config['excell_labels_2_names'],\n",
    "    stereo2mono=True,\n",
    "    overwrite=False,\n",
    "    sampling_rate=48000,\n",
    "    label_row_by_threshold=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# from copy import deepcopy\n",
    "# new_dataset_csv_backup = deepcopy(new_dataset_csv)\n",
    "# not_found_rows_backup = deepcopy(not_found_rows)\n",
    "\n",
    "# del not_found_rows_backup,new_dataset_csv_backup\n",
    "\n",
    "\n",
    "# write_csv(config['new_dataset_path'],\n",
    "#           new_dataset_csv,\n",
    "#           fieldnames=config['excell_all_headers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be48a4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3811"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff35e617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "dataset_csv_backup = deepcopy(dataset_csv)\n",
    "missing_csv_backup = deepcopy(missing_csv)\n",
    "\n",
    "excell_all_headers = [\n",
    "    'data_version', 'Annotator', 'Site ID', 'File Name', 'Date', 'Start Time',\n",
    "    'End Time', 'Length', 'Clip Path', 'Comments', 'weather_timestamp',\n",
    "    'region', 'day_length', 'air_temp', 'snow_depth', 'cloud_fraction',\n",
    "    'relative_humidity', 'runoff', 'rain_precip', 'snow_precip',\n",
    "    'wind_direction', 'wind_speed'\n",
    "]\n",
    "\n",
    "for row in dataset_csv_backup:\n",
    "    for k,v in row['weather_data'].items():\n",
    "        if k not in ['location','TIMESTAMP']:\n",
    "            row[k]=v\n",
    "        row['weather_timestamp'] = row['weather_data']['TIMESTAMP']\n",
    "    del row['weather_data']\n",
    "\n",
    "\n",
    "for row in dataset_csv_backup:\n",
    "    for k in list(row.keys()):\n",
    "        if k not in excell_all_headers:\n",
    "            del row[k]\n",
    "\n",
    "dataset_csv_unique = {}\n",
    "for row in dataset_csv_backup:\n",
    "    dataset_csv_unique[row['Clip Path']] = row\n",
    "dataset_csv_backup=list(dataset_csv_unique.values())\n",
    "\n",
    "print(len(dataset_csv_backup))\n",
    "teacher.write_csv(config['new_dataset_path'],\n",
    "          dataset_csv_backup,\n",
    "          fieldnames=excell_all_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dcd6c84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_version': 'W1',\n",
       " 'Annotator': 'weather_V1',\n",
       " 'Site ID': 'SINP03',\n",
       " 'File Name': '/tank/data/nna/real/ivvavik/SINP03/2019/SINP-03_20190513_231602.flac',\n",
       " 'Start Time': '00:29:50.000000',\n",
       " 'End Time': '00:30:00.000000',\n",
       " 'Date': '05/14/2019',\n",
       " 'Length': '00:00:10.000000',\n",
       " 'Clip Path': PosixPath('/scratch/enis/data/nna/labeling/samples/weather_V1/audio_weather_V1/ivvavik/SINP03/SINP-03_20190513_231602_73m_48s__73m_58s.wav'),\n",
       " 'Comments': '',\n",
       " 'weather_timestamp': '2019-05-14_01:30:00',\n",
       " 'region': 'ivvavik',\n",
       " 'day_length': 20.2996368,\n",
       " 'air_temp': 0.922241211,\n",
       " 'snow_depth': 0.450530827,\n",
       " 'cloud_fraction': 0.831612885,\n",
       " 'relative_humidity': 84.5013275,\n",
       " 'runoff': 0.0,\n",
       " 'rain_precip': 3.24604343e-06,\n",
       " 'snow_precip': 4.02112619e-06,\n",
       " 'wind_direction': 291.185028,\n",
       " 'wind_speed': 1.36716318}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_csv_backup[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bd225c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae7383de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3935"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8e322b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[row['Clip Path'] for row in dataset_csv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4058b400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3811, 3700)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len((a)),len(set(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95d8f3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_version': 'W2', 'Annotator': 'weather_V2', 'Site ID': '03', 'File Name': '/tank/data/nna/real/dalton/03/2019/S4A10437_20191009_172000.aac', 'Start Time': '17:20:00.000000', 'End Time': '17:20:10.000000', 'Date': '10/09/2019', 'Length': '00:00:10.000000', 'Clip Path': PosixPath('/scratch/enis/data/nna/labeling/samples/weather_V2/audio_weather_V2/dalton/03/S4A10437_20191009_172000_0m_0s__0m_10s.wav'), 'Comments': '', 'weather_timestamp': '2019-10-09_16:30:00', 'region': 'dalton', 'day_length': 9.85344791, 'air_temp': -0.127105713, 'snow_depth': 0.0195905175, 'cloud_fraction': 0.831612885, 'relative_humidity': 95.3483429, 'runoff': 0.0, 'rain_precip': 1.14912109e-05, 'snow_precip': 7.56504087e-05, 'total_precip': 8.71416196e-05, 'wind_direction': 192.373138, 'wind_speed': 1.04121852, 'snow_blowing_ground': 0.0, 'snow_blowing_air': 0.0787686035}\n"
     ]
    }
   ],
   "source": [
    "for row in dataset_csv:\n",
    "    m = row['Clip Path']\n",
    "    if m.exists():\n",
    "        continue\n",
    "    else:\n",
    "        print(row)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cbe570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
