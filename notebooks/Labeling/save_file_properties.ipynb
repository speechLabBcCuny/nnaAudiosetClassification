{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collects data for file_properties_df.\\n\\nfile_properties_df holds metadata about data in our dataset, \\ndetails of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset, \n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nna.fileUtils import list_files,getLength,read_file_properties_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Programs\n",
    "# ffprobe version >= 4.3.1  \n",
    "ffprobe_path = '/home/enis/sbin/ffprobe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for new DATABASE\n",
    "\n",
    "# increase version number accordinly \n",
    "previous_database_ver_str = 'V9'\n",
    "new_database_ver_str = 'V10'\n",
    "\n",
    "# where to save txt file storing length info\n",
    "# old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "data_folder = '/scratch/enis/data/nna/database/'\n",
    "#/scratch/enis/data/nna/database\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "search_path=\"/tank/data/nna/real/\"\n",
    "\n",
    "ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\n",
    "                \"/tank/data/nna/real/stinchcomb/excerpts/\",\n",
    "                \"/tank/data/nna/real/stinchcomb/\"]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARAMETERS for external or small inferences\n",
    "\n",
    "# # PARAMETERS  \n",
    "\n",
    "# # increase version number accordinly \n",
    "# previous_database_ver_str = ''\n",
    "# new_database_ver_str = 'V1'\n",
    "\n",
    "# # where to save txt file storing length info\n",
    "# # old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "# # data_folder = '/scratch/enis/data/nna/database/'\n",
    "# data_folder = '/scratch/enis/data/nna/collar_database/'\n",
    "\n",
    "# #/scratch/enis/data/nna/database\n",
    "\n",
    "# # path to search for audio files\n",
    "# # where\n",
    "# # ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "# # search_path=\"/tank/data/nna/real/\"\n",
    "# search_path = '/tank/data/nna/audio_collars/'\n",
    "\n",
    "# ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# # search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Relative Path names\n",
    "\n",
    "# if we already have a list of files we can load them \n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path=data_folder+ f\"allFields_path{new_database_ver_str}.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file, \n",
    "# we can load them\n",
    "fileswlen_path = data_folder+ f\"allFields_wlen_f{new_database_ver_str}.txt\"\n",
    "filesWError_out = data_folder+f\"allFields_wERROR_f{new_database_ver_str}.txt\"\n",
    "\n",
    "# do NOT add pkl extension at the end\n",
    "pkl_file_name=f\"allFields_data{new_database_ver_str}\"\n",
    "\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = data_folder + f\"allFields_data{previous_database_ver_str}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/enis/data/nna/database/allFields_dataV9.pkl'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_pkl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if Path(fileswlen_path).exists():\n",
    "    with open(files_list_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        files_path_list=[line.strip() for line in lines]\n",
    "else:\n",
    "    files_path_list=list_files(search_path,ignore_folders)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example file: /tank/data/nna/real/anwr/31/2019/S4A10297_20190504_000000.flac\n",
      "total number of files: 255714\n"
     ]
    }
   ],
   "source": [
    "print('example file:',files_path_list[0])\n",
    "print('total number of files:',len(files_path_list))\n",
    "assert Path(files_path_list[0]).is_dir()==False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.flac': 255714})\n"
     ]
    }
   ],
   "source": [
    "# count file extensions\n",
    "suffix2files={}\n",
    "\n",
    "files_suffixes=[]\n",
    "for m in files_path_list:\n",
    "    m=Path(m)\n",
    "    mSuffix = m.suffix.lower()\n",
    "    \n",
    "    files_suffixes.append(mSuffix)\n",
    "    suffix2files.setdefault(mSuffix,[]).append(m)\n",
    "\n",
    "        \n",
    "print(Counter(files_suffixes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n",
    "#V7: Counter({'.flac': 204692, '.aac': 9101, '.wav': 2340, '.mp3': 388, '.txt': 3, '.flac~': 1, '.filepart': 1})\n",
    "\n",
    "#V8: Counter({'.flac': 227227, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.filepart': 1, '.txt': 1})\n",
    "\n",
    "#V10: Counter({'.flac': 259798})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does NOT exists /scratch/enis/data/nna/database/allFields_dataV9.pkl\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load previous data\n",
    "if Path(current_pkl_file+'non').exists() :\n",
    "\n",
    "    current_file_properties_df=pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "    # remove files we already know about\n",
    "    currentFileSet = set(current_file_properties_df.index)\n",
    "    currentFileSet = set([str(m) for m in currentFileSet])\n",
    "    foundFileSet = set(files_path_list)\n",
    "    foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "    New_files_path_list = list(foundFileSet)\n",
    "    a_str=\"new\",len(New_files_path_list),\"previously\",len(currentFileSet),\"total\",len(files_path_list)\n",
    "    print(a_str)\n",
    "else:\n",
    "    print('does NOT exists',current_pkl_file)\n",
    "    New_files_path_list = files_path_list[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load or calculate Audio length\n",
    "import pickle\n",
    "\n",
    "\n",
    "filesWError = []\n",
    "\n",
    "length_dict = {}\n",
    "c=0\n",
    "for f in New_files_path_list:\n",
    "    if c % 1000 == 0:\n",
    "        print(c/len(New_files_path_list))\n",
    "    c+=1\n",
    "    length=float(getLength(f))\n",
    "    length_dict[f]=length\n",
    "\n",
    "\n",
    "fileswlen=length_dict\n",
    "\n",
    "# with open('fileswlen.pickle', 'wb') as handle:\n",
    "#     pickle.dump(fileswlen, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "# with open('fileswlen.pickle', 'rb') as handle:\n",
    "#     fileswlen = pickle.load(handle)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileswlen_filtered={}\n",
    "for f,length in fileswlen.items():\n",
    "    if 'dalton/09/2021/9/' in f:\n",
    "        continue\n",
    "    else:\n",
    "        fileswlen_filtered[f]=length\n",
    "fileswlen = fileswlen_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesWError=[]\n",
    "for f,length in fileswlen.items():\n",
    "    if length==-1:\n",
    "        filesWError.append(f)\n",
    "    \n",
    "\n",
    "assert len(filesWError)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "\n",
    "print(len(filesWError))\n",
    "with open(filesWError_out,\"w\") as f:\n",
    "    for line in filesWError:\n",
    "        join_lines = [str(i) for i in line]\n",
    "        f.write(\",\".join(join_lines)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties\n",
    "file_properties,exceptions = read_file_properties_v2(list(fileswlen.keys()),debug=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([tuple(str(ex).split(\"/\")[5:7]) for ex in exceptions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 255714)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions),len(New_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,lengthSeconds in fileswlen.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "    else:\n",
    "        print(\"file not found\",f)\n",
    "file_properties_df=pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (file_properties_df[file_properties_df['durationSec']>0]).shape==file_properties_df.shape\n",
    "## ignore files with 0 length\n",
    "# file_properties_df = file_properties_df[file_properties_df['durationSec']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## these files are too short, I should investiage these\n",
    "# (file_properties_df[file_properties_df['durationSec']<21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat([file_properties_df,current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder+pkl_file_name+\"2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_properties_df=pd.read_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total days of recording 3536.5799098982093\n"
     ]
    }
   ],
   "source": [
    "print('total days of recording',((sum(current_file_properties_df['durationSec'])/3600)/24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "files_df_2019=current_file_properties_df[current_file_properties_df['year']=='2019']\n",
    "site_region=list({(val[1],val[0]) for val in  (files_df_2019[['locationId','region']].values)})\n",
    "site_region.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "\n",
    "cat '/scratch/enis/data/nna/flow_tracking/region-location-list_all-fields_datav10_without-stinchcomb.txt' | \\\n",
    "            parallel --csv -P 20 -n 1 -q python clipping_cli.py \\\n",
    "            --region {1} --location {2} --output_folder \\\n",
    "            '/scratch/enis/data/nna/clipping_info/all-merged_2021-10-28/' \\\n",
    "            --file_database '/scratch/enis/data/nna/database/allFields_dataV10.pkl' >>logs_2021-10-28.txt 2>&1 \\\n",
    "            && /scratch/enis/conda/envs/speechEnv/bin/python \\\n",
    "\t/home/enis/projects/nna/src/nna/slack_message.py \\\n",
    "\t -t \"cpu job ended\" -m 'clipping ended' \\\n",
    "\t|| /scratch/enis/conda/envs/speechEnv/bin/python \\\n",
    "\t/home/enis/projects/nna/src/nna/slack_message.py \\\n",
    "\t -t \"cpu job FAILED\" -m 'clipping FAILED'\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 anwr : 5 4 (M/D)\n",
      "32 anwr : 5 4 (M/D)\n",
      "33 anwr : 5 4 (M/D)\n",
      "34 anwr : 5 5 (M/D)\n",
      "35 anwr : 5 5 (M/D)\n",
      "36 anwr : 5 5 (M/D)\n",
      "37 anwr : 5 5 (M/D)\n",
      "38 anwr : 5 4 (M/D)\n",
      "39 anwr : 5 4 (M/D)\n",
      "40 anwr : 5 4 (M/D)\n",
      "41 anwr : 5 5 (M/D)\n",
      "42 anwr : 5 5 (M/D)\n",
      "43 anwr : 5 5 (M/D)\n",
      "44 anwr : 5 5 (M/D)\n",
      "45 anwr : 5 5 (M/D)\n",
      "46 anwr : 5 4 (M/D)\n",
      "47 anwr : 5 5 (M/D)\n",
      "48 anwr : 5 5 (M/D)\n",
      "49 anwr : 5 5 (M/D)\n",
      "50 anwr : 5 5 (M/D)\n",
      "01 dalton : 3 16 (M/D)\n",
      "02 dalton : 3 16 (M/D)\n",
      "03 dalton : 3 16 (M/D)\n",
      "04 dalton : 3 16 (M/D)\n",
      "05 dalton : 3 16 (M/D)\n",
      "06 dalton : 3 17 (M/D)\n",
      "07 dalton : 3 17 (M/D)\n",
      "08 dalton : 3 17 (M/D)\n",
      "09 dalton : 3 17 (M/D)\n",
      "10 dalton : 3 18 (M/D)\n",
      "11 dempster : 7 20 (M/D)\n",
      "12 dempster : 3 23 (M/D)\n",
      "13 dempster : 3 23 (M/D)\n",
      "14 dempster : 3 23 (M/D)\n",
      "15 dempster : 3 23 (M/D)\n",
      "16 dempster : 3 23 (M/D)\n",
      "17 dempster : 3 24 (M/D)\n",
      "19 dempster : 3 24 (M/D)\n",
      "20 dempster : 3 24 (M/D)\n",
      "21 dempster : 3 24 (M/D)\n",
      "22 dempster : 3 26 (M/D)\n",
      "23 dempster : 3 26 (M/D)\n",
      "24 dempster : 3 26 (M/D)\n",
      "25 dempster : 3 26 (M/D)\n",
      "AR01 ivvavik : 5 2 (M/D)\n",
      "AR02 ivvavik : 5 2 (M/D)\n",
      "AR03 ivvavik : 5 2 (M/D)\n",
      "AR04 ivvavik : 5 2 (M/D)\n",
      "AR05 ivvavik : 5 2 (M/D)\n",
      "AR06 ivvavik : 4 29 (M/D)\n",
      "AR07 ivvavik : 5 3 (M/D)\n",
      "AR08 ivvavik : 5 3 (M/D)\n",
      "AR09 ivvavik : 5 3 (M/D)\n",
      "AR10 ivvavik : 5 3 (M/D)\n",
      "SINP01 ivvavik : 5 3 (M/D)\n",
      "SINP02 ivvavik : 5 3 (M/D)\n",
      "SINP03 ivvavik : 5 3 (M/D)\n",
      "SINP04 ivvavik : 5 3 (M/D)\n",
      "SINP05 ivvavik : 5 3 (M/D)\n",
      "SINP06 ivvavik : 5 4 (M/D)\n",
      "SINP07 ivvavik : 5 4 (M/D)\n",
      "SINP08 ivvavik : 5 4 (M/D)\n",
      "SINP09 ivvavik : 5 4 (M/D)\n",
      "SINP10 ivvavik : 5 4 (M/D)\n",
      "11 prudhoe : 5 7 (M/D)\n",
      "12 prudhoe : 5 6 (M/D)\n",
      "13 prudhoe : 5 6 (M/D)\n",
      "14 prudhoe : 5 6 (M/D)\n",
      "15 prudhoe : 5 6 (M/D)\n",
      "16 prudhoe : 5 6 (M/D)\n",
      "17 prudhoe : 5 6 (M/D)\n",
      "18 prudhoe : 5 6 (M/D)\n",
      "19 prudhoe : 5 4 (M/D)\n",
      "20 prudhoe : 5 4 (M/D)\n",
      "21 prudhoe : 5 4 (M/D)\n",
      "22 prudhoe : 5 7 (M/D)\n",
      "23 prudhoe : 5 7 (M/D)\n",
      "24 prudhoe : 5 7 (M/D)\n",
      "25 prudhoe : 5 6 (M/D)\n",
      "26 prudhoe : 5 3 (M/D)\n",
      "27 prudhoe : 5 4 (M/D)\n",
      "28 prudhoe : 5 4 (M/D)\n",
      "29 prudhoe : 5 7 (M/D)\n",
      "30 prudhoe : 5 7 (M/D)\n"
     ]
    }
   ],
   "source": [
    "for region,site_id in site_region:\n",
    "    site_files_df_2019=files_df_2019[files_df_2019['site_id']==site_id]\n",
    "    region_files_df_2019=site_files_df_2019[site_files_df_2019['region']==region]\n",
    "    t=region_files_df_2019['timestamp'].sort_values()[0]\n",
    "    print(site_id,region,':',t.month,t.day,'(M/D)')\n",
    "    # print(region_files_df_2019['timestamp'].sort_values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 5, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
