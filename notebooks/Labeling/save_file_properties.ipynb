{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset,\n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82ef0904b234cb2901384312044084e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nna.fileUtils import list_files, concurrent_get_media_duration, read_file_properties_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Programs\n",
    "# ffprobe version >= 4.3.1\n",
    "ffprobe_path = '/home/enis/sbin/ffprobe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for new DATABASE\n",
    "\n",
    "# increase version number accordinly\n",
    "previous_database_ver_str = 'V102'\n",
    "new_database_ver_str = 'Vtodd'\n",
    "# where to save txt file storing length info\n",
    "# old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "data_folder = '/scratch/enis/data/nna/database/'\n",
    "#/scratch/enis/data/nna/database\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "# search_path = \"/tank/data/nna/real/\"\n",
    "search_path = '/tank/data/nna/recover_files/2022/'\n",
    "ignore_folders = [\n",
    "    \"/tank/data/nna/real/stinchcomb/dups/\",\n",
    "    \"/tank/data/nna/real/stinchcomb/excerpts/\",\n",
    "    \"/tank/data/nna/real/stinchcomb/\"\n",
    "]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARAMETERS for external or small inferences\n",
    "\n",
    "# # PARAMETERS\n",
    "\n",
    "# # increase version number accordinly\n",
    "# previous_database_ver_str = ''\n",
    "# new_database_ver_str = 'V1'\n",
    "\n",
    "# # where to save txt file storing length info\n",
    "# # old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "# # data_folder = '/scratch/enis/data/nna/database/'\n",
    "# data_folder = '/scratch/enis/data/nna/collar_database/'\n",
    "\n",
    "# #/scratch/enis/data/nna/database\n",
    "\n",
    "# # path to search for audio files\n",
    "# # where\n",
    "# # ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "# # search_path=\"/tank/data/nna/real/\"\n",
    "# search_path = '/tank/data/nna/audio_collars/'\n",
    "\n",
    "# ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# # search_path=\"/tank/data/nna/real/stinchcomb/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/enis/data/nna/database/allFields_dataV102.pkl\n"
     ]
    }
   ],
   "source": [
    "# create Relative Path names\n",
    "\n",
    "# if we already have a list of files we can load them\n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path = data_folder + f\"allFields_path{new_database_ver_str}.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file,\n",
    "# we can load them\n",
    "fileswlen_path = data_folder + f\"allFields_wlen_f{new_database_ver_str}.txt\"\n",
    "filesWError_out = data_folder + f\"allFields_wERROR_f{new_database_ver_str}.txt\"\n",
    "\n",
    "# do NOT add pkl extension at the end\n",
    "pkl_file_name = f\"allFields_data{new_database_ver_str}\"\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = data_folder + f\"allFields_data{previous_database_ver_str}.pkl\"\n",
    "print(current_pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if Path(fileswlen_path).exists():\n",
    "    with open(files_list_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        files_path_list = [line.strip() for line in lines]\n",
    "else:\n",
    "    files_path_list = list_files(search_path, ignore_folders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example file: /tank/data/nna/recover_files/2022/folders_and_files_tree.txt\n",
      "total number of files: 16628\n"
     ]
    }
   ],
   "source": [
    "print('example file:', files_path_list[0])\n",
    "print('total number of files:', len(files_path_list))\n",
    "assert Path(files_path_list[0]).is_dir() == False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.wav': 16523, '.sm4dump': 79, '.txt': 25, '.csv': 1})\n"
     ]
    }
   ],
   "source": [
    "# count file extensions\n",
    "suffix2files = {}\n",
    "\n",
    "files_suffixes = []\n",
    "for m in files_path_list:\n",
    "    m = Path(m)\n",
    "    mSuffix = m.suffix.lower()\n",
    "    files_suffixes.append(mSuffix)\n",
    "    suffix2files.setdefault(mSuffix, []).append(m)\n",
    "\n",
    "print(Counter(files_suffixes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n",
    "#V7: Counter({'.flac': 204692, '.aac': 9101, '.wav': 2340, '.mp3': 388, '.txt': 3, '.flac~': 1, '.filepart': 1})\n",
    "\n",
    "#V8: Counter({'.flac': 227227, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.filepart': 1, '.txt': 1})\n",
    "\n",
    "#V10: Counter({'.flac': 259798})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "does NOT exists /scratch/enis/data/nna/database/allFields_dataV102.pkl\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "if Path(current_pkl_file).exists():\n",
    "\n",
    "    current_file_properties_df = pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "    # remove files we already know about\n",
    "    currentFileSet = set(current_file_properties_df.index)\n",
    "    currentFileSet = set([str(m) for m in currentFileSet])\n",
    "    foundFileSet = set(files_path_list)\n",
    "    foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "    New_files_path_list = list(foundFileSet)\n",
    "    a_str = \"new\", len(New_files_path_list), \"previously\", len(\n",
    "        currentFileSet), \"total\", len(files_path_list)\n",
    "    print(a_str)\n",
    "else:\n",
    "    print('does NOT exists', current_pkl_file)\n",
    "    only_wav = [m for m in files_path_list if Path(m).suffix == '.wav']\n",
    "    New_files_path_list = only_wav[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16523"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(New_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.00%\n",
      "Progress: 6.05%\n",
      "Progress: 12.10%\n",
      "Progress: 18.16%\n",
      "Progress: 24.21%\n",
      "Progress: 30.26%\n",
      "Progress: 36.31%\n",
      "Progress: 42.37%\n",
      "Progress: 48.42%\n",
      "Progress: 54.47%\n",
      "Progress: 60.52%\n",
      "Progress: 66.57%\n",
      "Progress: 72.63%\n",
      "Progress: 78.68%\n",
      "Progress: 84.73%\n",
      "Progress: 90.78%\n",
      "Progress: 96.83%\n"
     ]
    }
   ],
   "source": [
    "# usage\n",
    "length_dict, filesWError = concurrent_get_media_duration(New_files_path_list)\n",
    "# print('Files with duration:', length_dict)\n",
    "# print('Files with errors:', filesWError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filesWError\n",
    "# #\n",
    "# for i in filesWError:\n",
    "#     print(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tank/data/nna/recover_files/2022/region/11/2022/S4A10276_20220801_130002.wav',\n",
       " \"Command '['/scratch/enis/conda/envs/speechEnv/bin/ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', '/tank/data/nna/recover_files/2022/region/11/2022/S4A10276_20220801_130002.wav']' returned non-zero exit status 1.\")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesWError[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114\n",
      "saved /scratch/enis/data/nna/database/allFields_wERROR_fVtodd.txt\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "print(len(filesWError))\n",
    "with open(filesWError_out, \"w\") as f:\n",
    "    lines = [line[0] for line in filesWError]\n",
    "    f.write(\"\\n\".join(lines) + \"\\n\")\n",
    "print('saved', filesWError_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tank/data/nna/recover_files/2022/region/11/2022/S4A10276_20220801_130002.wav',\n",
       " \"Command '['/scratch/enis/conda/envs/speechEnv/bin/ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', '/tank/data/nna/recover_files/2022/region/11/2022/S4A10276_20220801_130002.wav']' returned non-zero exit status 1.\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesWError[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = length_dict.copy()\n",
    "\n",
    "new_test = {}\n",
    "for key, value in test.items():\n",
    "    key = Path(key)\n",
    "    key = (key.parts[:5] + key.parts[6:])\n",
    "    key = Path(*key)\n",
    "    new_test[key] = value\n",
    "    # print(len(key.parents))\n",
    "    # print(key.parts)\n",
    "    # print(key.parts[6])\n",
    "    # print(key.parts[5])\n",
    "    # break\n",
    "# new_test = {Path(*Path(key).parts[2:]): value for key, value in test.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_130002.wav')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(new_test.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties\n",
    "file_properties, exceptions = read_file_properties_v2(list(new_test.keys()),\n",
    "                                                      debug=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set([tuple(str(ex).split(\"/\")[5:7]) for ex in exceptions])\n",
    "# Splitting the path into its components\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 16523)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions), len(New_files_path_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, lengthSeconds in new_test.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(\n",
    "            f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "    else:\n",
    "        print(\"file not found\", f)\n",
    "file_properties_df = pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df['locationId'] = file_properties_df['region']\n",
    "file_properties_df['region'] = 'region'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>locationId</th>\n",
       "      <th>site_name</th>\n",
       "      <th>recorderId</th>\n",
       "      <th>hour_min_sec</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>region</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationSec</th>\n",
       "      <th>timestampEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/11/2022/S4A10276_20220815_130002.wav</th>\n",
       "      <td>11</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10276</td>\n",
       "      <td>130002</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>15</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-15 13:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-08-15 13:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/11/2022/S4A10276_20220714_140002.wav</th>\n",
       "      <td>11</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10276</td>\n",
       "      <td>140002</td>\n",
       "      <td>2022</td>\n",
       "      <td>07</td>\n",
       "      <td>14</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-07-14 14:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-07-14 14:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/11/2022/S4A10276_20220731_090002.wav</th>\n",
       "      <td>11</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10276</td>\n",
       "      <td>090002</td>\n",
       "      <td>2022</td>\n",
       "      <td>07</td>\n",
       "      <td>31</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-07-31 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-07-31 09:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/11/2022/S4A10276_20220815_120000.wav</th>\n",
       "      <td>11</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10276</td>\n",
       "      <td>120000</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>15</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-15 12:00:00</td>\n",
       "      <td>3599.998549</td>\n",
       "      <td>2022-08-15 12:59:59.998549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/11/2022/S4A10276_20220717_030002.wav</th>\n",
       "      <td>11</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10276</td>\n",
       "      <td>030002</td>\n",
       "      <td>2022</td>\n",
       "      <td>07</td>\n",
       "      <td>17</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-07-17 03:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-07-17 03:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/35/2022/S4A10272_20220830_200002.wav</th>\n",
       "      <td>35</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10272</td>\n",
       "      <td>200002</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>30</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-30 20:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-08-30 20:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/35/2022/S4A10272_20220829_110004.wav</th>\n",
       "      <td>35</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10272</td>\n",
       "      <td>110004</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>29</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-29 11:00:04</td>\n",
       "      <td>3595.998912</td>\n",
       "      <td>2022-08-29 11:59:59.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/35/2022/S4A10272_20220825_090002.wav</th>\n",
       "      <td>35</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10272</td>\n",
       "      <td>090002</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>25</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-25 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-08-25 09:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/35/2022/S4A10272_20220831_020002.wav</th>\n",
       "      <td>35</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10272</td>\n",
       "      <td>020002</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>31</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-31 02:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-08-31 02:59:59.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>/tank/data/nna/recover_files/region/35/2022/S4A10272_20220827_090002.wav</th>\n",
       "      <td>35</td>\n",
       "      <td>region</td>\n",
       "      <td></td>\n",
       "      <td>S4A10272</td>\n",
       "      <td>090002</td>\n",
       "      <td>2022</td>\n",
       "      <td>08</td>\n",
       "      <td>27</td>\n",
       "      <td>region</td>\n",
       "      <td>2022-08-27 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "      <td>2022-08-27 09:59:59.995828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16409 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   site_id locationId  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...      11     region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...      11     region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...      11     region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...      11     region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...      11     region   \n",
       "...                                                    ...        ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...      35     region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...      35     region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...      35     region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...      35     region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...      35     region   \n",
       "\n",
       "                                                   site_name recorderId  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...             S4A10276   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...             S4A10276   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...             S4A10276   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...             S4A10276   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...             S4A10276   \n",
       "...                                                      ...        ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...             S4A10272   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...             S4A10272   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...             S4A10272   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...             S4A10272   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...             S4A10272   \n",
       "\n",
       "                                                   hour_min_sec  year month  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...       130002  2022    08   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...       140002  2022    07   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...       090002  2022    07   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...       120000  2022    08   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...       030002  2022    07   \n",
       "...                                                         ...   ...   ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...       200002  2022    08   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...       110004  2022    08   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...       090002  2022    08   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...       020002  2022    08   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...       090002  2022    08   \n",
       "\n",
       "                                                   day  region  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  15  region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  14  region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  31  region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  15  region   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  17  region   \n",
       "...                                                 ..     ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  30  region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  29  region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  25  region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  31  region   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  27  region   \n",
       "\n",
       "                                                             timestamp  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-08-15 13:00:02   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-14 14:00:02   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-31 09:00:02   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-08-15 12:00:00   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-17 03:00:02   \n",
       "...                                                                ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-30 20:00:02   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-29 11:00:04   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-25 09:00:02   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-31 02:00:02   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-27 09:00:02   \n",
       "\n",
       "                                                    durationSec  \\\n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  3599.998549   \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A...  3597.995828   \n",
       "...                                                         ...   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  3595.998912   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  3597.995828   \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A...  3597.995828   \n",
       "\n",
       "                                                                 timestampEnd  \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-08-15 13:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-14 14:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-31 09:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-08-15 12:59:59.998549  \n",
       "/tank/data/nna/recover_files/region/11/2022/S4A... 2022-07-17 03:59:59.995828  \n",
       "...                                                                       ...  \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-30 20:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-29 11:59:59.998912  \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-25 09:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-31 02:59:59.995828  \n",
       "/tank/data/nna/recover_files/region/35/2022/S4A... 2022-08-27 09:59:59.995828  \n",
       "\n",
       "[16409 rows x 12 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (file_properties_df[file_properties_df['durationSec'] > 0]\n",
    "       ).shape == file_properties_df.shape\n",
    "## ignore files with 0 length\n",
    "# file_properties_df = file_properties_df[file_properties_df['durationSec']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "## these files are too short, I should investiage these\n",
    "# (file_properties_df[file_properties_df['durationSec']<21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat(\n",
    "    [file_properties_df, current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \"2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_properties_df = pd.read_pickle(data_folder + pkl_file_name +\n",
    "                                            \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total days of recording 3536.5799098982093\n"
     ]
    }
   ],
   "source": [
    "print('total days of recording',\n",
    "      ((sum(current_file_properties_df['durationSec']) / 3600) / 24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "files_df_2019 = current_file_properties_df[current_file_properties_df['year'] ==\n",
    "                                           '2019']\n",
    "site_region = list({\n",
    "    (val[1], val[0]) for val in (files_df_2019[['locationId', 'region']].values)\n",
    "})\n",
    "site_region.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, site_id in site_region:\n",
    "    site_files_df_2019 = files_df_2019[files_df_2019['site_id'] == site_id]\n",
    "    region_files_df_2019 = site_files_df_2019[site_files_df_2019['region'] ==\n",
    "                                              region]\n",
    "    t = region_files_df_2019['timestamp'].sort_values()[0]\n",
    "    print(site_id, region, ':', t.month, t.day, '(M/D)')\n",
    "    # print(region_files_df_2019['timestamp'].sort_values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>locationId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_130002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 13:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220714_140002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-14 14:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220731_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-31 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_120000.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 12:00:00</td>\n",
       "      <td>3599.998549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220717_030002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-17 03:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220830_200002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-30 20:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220829_110004.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-29 11:00:04</td>\n",
       "      <td>3595.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220825_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-25 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220831_020002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-31 02:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220827_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-27 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16409 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   site_id locationId  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "...                                                    ...        ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "\n",
       "                                                             timestamp  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 13:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-14 14:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-31 09:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 12:00:00   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-17 03:00:02   \n",
       "...                                                                ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-30 20:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-29 11:00:04   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-25 09:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-31 02:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-27 09:00:02   \n",
       "\n",
       "                                                    durationSec  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3599.998549  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "...                                                         ...  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3595.998912  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "\n",
       "[16409 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df[['site_id', 'locationId', 'timestamp', 'durationSec']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the duration from seconds to hours\n",
    "file_properties_df['durationHours'] = file_properties_df['durationSec'] / 3600\n",
    "\n",
    "# Group by site_id and locationId, then sum the durations\n",
    "result = file_properties_df.groupby([\n",
    "    'site_id',\n",
    "])['durationHours'].sum().reset_index()\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/duration.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id  month  durationHours\n",
      "0       11      7     323.808829\n",
      "1       11      8     360.786849\n",
      "2       11      9      34.830630\n",
      "3       12      7     323.809384\n",
      "4       12      8     336.804094\n",
      "..     ...    ...            ...\n",
      "62      34      8     367.783506\n",
      "63      34      9       2.999442\n",
      "64      35      8     305.820790\n",
      "65      35      7     311.816896\n",
      "66      35      9       4.997773\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = file_properties_df.copy()\n",
    "# Convert timestamp column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract year and month\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Group by site_id, locationId, year and month, then sum the durations\n",
    "result = df.groupby(['site_id', 'month'])['durationHours'].sum().reset_index()\n",
    "\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/durations_bymonth.csv',\n",
    "              index=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soundenv3",
   "language": "python",
   "name": "soundenv3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
