{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collects data for file_properties_df.\\n\\nfile_properties_df holds metadata about data in our dataset, \\ndetails of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset, \n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84bbf3cbfa9f48789f3260e44f7b819d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nna.fileUtils import list_files,getLength,read_file_properties_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Programs\n",
    "# ffprobe version >= 4.3.1  \n",
    "ffprobe_path = '/home/enis/sbin/ffprobe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for new DATABASE\n",
    "\n",
    "# increase version number accordinly \n",
    "previous_database_ver_str = 'V8'\n",
    "new_database_ver_str = 'V9'\n",
    "\n",
    "# where to save txt file storing length info\n",
    "# old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "data_folder = '/scratch/enis/data/nna/database/'\n",
    "#/scratch/enis/data/nna/database\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "search_path=\"/tank/data/nna/real/\"\n",
    "\n",
    "ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARAMETERS for external or small inferences\n",
    "\n",
    "# # PARAMETERS  \n",
    "\n",
    "# # increase version number accordinly \n",
    "# previous_database_ver_str = ''\n",
    "# new_database_ver_str = 'V1'\n",
    "\n",
    "# # where to save txt file storing length info\n",
    "# # old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "# # data_folder = '/scratch/enis/data/nna/database/'\n",
    "# data_folder = '/scratch/enis/data/nna/collar_database/'\n",
    "\n",
    "# #/scratch/enis/data/nna/database\n",
    "\n",
    "# # path to search for audio files\n",
    "# # where\n",
    "# # ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "# # search_path=\"/tank/data/nna/real/\"\n",
    "# search_path = '/tank/data/nna/audio_collars/'\n",
    "\n",
    "# ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# # search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Relative Path names\n",
    "\n",
    "# if we already have a list of files we can load them \n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path=data_folder+ f\"allFields_path{new_database_ver_str}.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file, \n",
    "# we can load them\n",
    "fileswlen_path = data_folder+ f\"allFields_wlen_f{new_database_ver_str}.txt\"\n",
    "filesWError_out = data_folder+f\"allFields_wERROR_f{new_database_ver_str}.txt\"\n",
    "\n",
    "# do NOT add pkl extension at the end\n",
    "pkl_file_name=f\"allFields_data{new_database_ver_str}\"\n",
    "\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = data_folder + f\"allFields_data{previous_database_ver_str}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.48 s, sys: 344 ms, total: 1.82 s\n",
      "Wall time: 2.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if not Path(fileswlen_path).exists():\n",
    "    files_path_list=list_files(search_path,ignore_folders)\n",
    "else:\n",
    "    with open(files_list_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        files_path_list=[line.strip() for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example file /tank/data/nna/real/anwr/31/2019/S4A10297_20190504_000000.flac\n"
     ]
    }
   ],
   "source": [
    "print('example file',files_path_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(files_path_list[0]).is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.flac': 237518, '.wav': 10290, '.aac': 9101, '.mp3': 388, '.txt': 6, '.flac~': 1, '.filepart': 1})\n"
     ]
    }
   ],
   "source": [
    "# count file extension and filter if required\n",
    "\n",
    "files_suffixes=[]\n",
    "files_path_list_filtered=[]\n",
    "for m in files_path_list:\n",
    "    m=Path(m)\n",
    "    if m.is_dir():\n",
    "        continue\n",
    "    mSuffix = m.suffix.lower()\n",
    "    \n",
    "    files_suffixes.append(mSuffix)\n",
    "    m_str=str(m).lower()\n",
    "    \n",
    "    if \"~\" in m_str:\n",
    "        continue\n",
    "    if \"filepart\" in m_str:\n",
    "        continue\n",
    "    if \".txt\" in m_str:\n",
    "        continue\n",
    "    if 'wav' in m_str:\n",
    "        continue\n",
    "#     if mSuffix!=\".flac\" and mSuffix!=\".aac\" and mSuffix!=\".mp3\":\n",
    "#         print(m)\n",
    "#         break\n",
    "    files_path_list_filtered.append((m))\n",
    "        \n",
    "print(Counter(files_suffixes))\n",
    "files_path_list = files_path_list_filtered[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n",
    "#V7: Counter({'.flac': 204692, '.aac': 9101, '.wav': 2340, '.mp3': 388, '.txt': 3, '.flac~': 1, '.filepart': 1})\n",
    "\n",
    "#V8: Counter({'.flac': 227227, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.filepart': 1, '.txt': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new', 16564, 'previously', 230443, 'total', 247007)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load previous data\n",
    "if Path(current_pkl_file).exists() :\n",
    "\n",
    "    current_file_properties_df=pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "    # remove files we already know about\n",
    "    currentFileSet = set(current_file_properties_df.index)\n",
    "    foundFileSet = set(files_path_list)\n",
    "    foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "    New_files_path_list = list(foundFileSet)\n",
    "    a_str=\"new\",len(New_files_path_list),\"previously\",len(currentFileSet),\"total\",len(files_path_list)\n",
    "    print(a_str)\n",
    "else:\n",
    "    print('does NOT exists',current_pkl_file)\n",
    "    New_files_path_list = files_path_list[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_files_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR file is too short /tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac\n",
      "command run with ERROR: ['/home/enis/sbin/ffprobe', '-i', '/tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac', '-show_entries', 'format=duration', '-v', 'quiet']\n"
     ]
    }
   ],
   "source": [
    "# Load or calculate Audio length\n",
    "import subprocess\n",
    "\n",
    "filesWError = []\n",
    "\n",
    "# learn length of each audio and store in a text file, \n",
    "# if file already exists, it tries to get data from there\n",
    "if not Path(fileswlen_path).exists():\n",
    "    length_dict={}\n",
    "    for f in New_files_path_list:\n",
    "#         length=float(getLength(f))\n",
    "##################\n",
    "        input_video = f\n",
    "        \n",
    "        cmd=[]\n",
    "        cmd.extend( [ffprobe_path, '-i', '{}'.format(input_video), '-show_entries' ,'format=duration', '-v', 'quiet' ])\n",
    "        result = subprocess.Popen(cmd, stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "        output = result.communicate(b'\\n')\n",
    "        output = [i.decode('ascii') for i in output]\n",
    "        if output[0]==\"\":\n",
    "            length = -1\n",
    "            print(\"ERROR file is too short {}\".format(input_video))\n",
    "            print(\"command run with ERROR: {}\".format(cmd))\n",
    "            filesWError.append(input_video)\n",
    "        else:\n",
    "            length = output[0].split(\"\\n\")[1].split(\"=\")[1]\n",
    "###############\n",
    "        length_dict[f]=length\n",
    "\n",
    "    length_list=list(length_dict.items())\n",
    "    Path(fileswlen_path).parent.mkdir(parents=True,exist_ok=True)\n",
    "    with open(fileswlen_path,\"w\") as f:\n",
    "        for line in length_list:\n",
    "            join_lines = [str(i) for i in line]\n",
    "            f.write(\",\".join(join_lines)+\"\\n\")\n",
    "\n",
    "with open(fileswlen_path,\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    fileswlen=[line.strip().split(\",\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesWError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "\n",
    "print(len(filesWError))\n",
    "with open(filesWError_out,\"w\") as f:\n",
    "    for line in length_list:\n",
    "        join_lines = [str(i) for i in line]\n",
    "        f.write(\",\".join(join_lines)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fileswlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn results into a dict\n",
    "fileswlen=dict([(i[0],float(i[1])) for i in fileswlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties\n",
    "file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6273, 16564)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions),len(New_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/dalton/04/2021/S4A10281_20210922_120000.flac')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_files_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2timestamp(fileinfo_dict):\n",
    "    # x=file_properties[file]\n",
    "    #         print(x)\n",
    "    hour_min_sec = fileinfo_dict[\"hour_min_sec\"]\n",
    "    hour = int(hour_min_sec[:2])\n",
    "    minute = int(hour_min_sec[2:4])\n",
    "    second = int(hour_min_sec[4:6])\n",
    "    year = int(fileinfo_dict[\"year\"])\n",
    "\n",
    "    timestamp = datetime.datetime(year,\n",
    "                                  int(fileinfo_dict[\"month\"]),\n",
    "                                  int(fileinfo_dict[\"day\"]),\n",
    "                                  hour=hour,\n",
    "                                  minute=minute,\n",
    "                                  second=second,\n",
    "                                  microsecond=0)\n",
    "    fileinfo_dict[\"timestamp\"] = timestamp\n",
    "    return fileinfo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties[Path('/tank/data/nna/real/prudhoe/12/2021/S4A10265_20210706_060002.flac')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hard code file_path\n",
    "# file_properties = {}\n",
    "\n",
    "# for apath in New_files_path_list:\n",
    "#     startDateTime=apath.stem.split('_')\n",
    "#     date = startDateTime[0]\n",
    "#     year, month, day = date[0:4], date[4:6], date[6:8]\n",
    "#     hour_min_sec = startDateTime[1]\n",
    "\n",
    "#     # location_id = '149'\n",
    "#     # if '721' in str(apath):\n",
    "#     #     region = '721'\n",
    "#     # elif '781' in str(apath):\n",
    "#     #     region = '781'\n",
    "    \n",
    "#     site_name=''\n",
    "#     recorderId=''\n",
    "#     file_properties[apath] = str2timestamp({\n",
    "#                     \"site_id\": location_id,\n",
    "#                     \"locationId\": location_id,\n",
    "#                     \"site_name\": site_name,\n",
    "#                     \"recorderId\": recorderId,\n",
    "#                     \"hour_min_sec\": hour_min_sec,\n",
    "#                     \"year\": year,\n",
    "#                     \"month\": month,\n",
    "#                     \"day\": day,\n",
    "#                     \"region\": region\n",
    "#                 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n",
    "for f,lengthSeconds in fileswlen.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "file_properties_df=pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10291, 12) (10291, 12)\n"
     ]
    }
   ],
   "source": [
    "print((file_properties_df[file_properties_df['durationSec']>0]).shape,file_properties_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df = file_properties_df[file_properties_df['durationSec']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat([file_properties_df,current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently running servers:\n",
      "https://momentsnotice:8899/ :: /home/enis\n"
     ]
    }
   ],
   "source": [
    "!jupyter lab list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_properties_df=pd.read_pickle(str('/scratch/enis/data/nna/database/allFields_dataV9.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df_2019=current_file_properties_df[current_file_properties_df['year']=='2019']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2161.230985313189"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((sum(files_df_2019['durationSec'])/3600)/24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "site_region=list({(val[1],val[0]) for val in  (files_df_2019[['locationId','region']].values)})\n",
    "site_region.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# site_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 anwr : 5 4 (M/D)\n",
      "32 anwr : 5 4 (M/D)\n",
      "33 anwr : 5 4 (M/D)\n",
      "34 anwr : 5 5 (M/D)\n",
      "35 anwr : 5 5 (M/D)\n",
      "36 anwr : 5 5 (M/D)\n",
      "37 anwr : 5 5 (M/D)\n",
      "38 anwr : 5 4 (M/D)\n",
      "39 anwr : 5 4 (M/D)\n",
      "40 anwr : 5 4 (M/D)\n",
      "41 anwr : 5 5 (M/D)\n",
      "42 anwr : 5 5 (M/D)\n",
      "43 anwr : 5 5 (M/D)\n",
      "44 anwr : 5 5 (M/D)\n",
      "45 anwr : 5 5 (M/D)\n",
      "46 anwr : 5 4 (M/D)\n",
      "47 anwr : 5 5 (M/D)\n",
      "48 anwr : 5 5 (M/D)\n",
      "49 anwr : 5 5 (M/D)\n",
      "50 anwr : 5 5 (M/D)\n",
      "01 dalton : 3 16 (M/D)\n",
      "02 dalton : 3 16 (M/D)\n",
      "03 dalton : 3 16 (M/D)\n",
      "04 dalton : 3 16 (M/D)\n",
      "05 dalton : 3 16 (M/D)\n",
      "06 dalton : 3 17 (M/D)\n",
      "07 dalton : 3 17 (M/D)\n",
      "08 dalton : 3 17 (M/D)\n",
      "09 dalton : 3 17 (M/D)\n",
      "10 dalton : 3 18 (M/D)\n",
      "11 dempster : 7 20 (M/D)\n",
      "12 dempster : 3 23 (M/D)\n",
      "13 dempster : 3 23 (M/D)\n",
      "14 dempster : 3 23 (M/D)\n",
      "15 dempster : 3 23 (M/D)\n",
      "16 dempster : 3 23 (M/D)\n",
      "17 dempster : 3 24 (M/D)\n",
      "19 dempster : 3 24 (M/D)\n",
      "20 dempster : 3 24 (M/D)\n",
      "21 dempster : 3 24 (M/D)\n",
      "22 dempster : 3 26 (M/D)\n",
      "23 dempster : 3 26 (M/D)\n",
      "24 dempster : 3 26 (M/D)\n",
      "25 dempster : 3 26 (M/D)\n",
      "AR01 ivvavik : 5 2 (M/D)\n",
      "AR02 ivvavik : 5 2 (M/D)\n",
      "AR03 ivvavik : 5 2 (M/D)\n",
      "AR04 ivvavik : 5 2 (M/D)\n",
      "AR05 ivvavik : 5 2 (M/D)\n",
      "AR06 ivvavik : 4 29 (M/D)\n",
      "AR07 ivvavik : 5 3 (M/D)\n",
      "AR08 ivvavik : 5 3 (M/D)\n",
      "AR09 ivvavik : 5 3 (M/D)\n",
      "AR10 ivvavik : 5 3 (M/D)\n",
      "SINP01 ivvavik : 5 3 (M/D)\n",
      "SINP02 ivvavik : 5 3 (M/D)\n",
      "SINP03 ivvavik : 5 3 (M/D)\n",
      "SINP04 ivvavik : 5 3 (M/D)\n",
      "SINP05 ivvavik : 5 3 (M/D)\n",
      "SINP06 ivvavik : 5 4 (M/D)\n",
      "SINP07 ivvavik : 5 4 (M/D)\n",
      "SINP08 ivvavik : 5 4 (M/D)\n",
      "SINP09 ivvavik : 5 4 (M/D)\n",
      "SINP10 ivvavik : 5 4 (M/D)\n",
      "11 prudhoe : 5 7 (M/D)\n",
      "12 prudhoe : 5 6 (M/D)\n",
      "13 prudhoe : 5 6 (M/D)\n",
      "14 prudhoe : 5 6 (M/D)\n",
      "15 prudhoe : 5 6 (M/D)\n",
      "16 prudhoe : 5 6 (M/D)\n",
      "17 prudhoe : 5 6 (M/D)\n",
      "18 prudhoe : 5 6 (M/D)\n",
      "19 prudhoe : 5 4 (M/D)\n",
      "20 prudhoe : 5 4 (M/D)\n",
      "21 prudhoe : 5 4 (M/D)\n",
      "22 prudhoe : 5 7 (M/D)\n",
      "23 prudhoe : 5 7 (M/D)\n",
      "24 prudhoe : 5 7 (M/D)\n",
      "25 prudhoe : 5 6 (M/D)\n",
      "26 prudhoe : 5 3 (M/D)\n",
      "27 prudhoe : 5 4 (M/D)\n",
      "28 prudhoe : 5 4 (M/D)\n",
      "29 prudhoe : 5 7 (M/D)\n",
      "30 prudhoe : 5 7 (M/D)\n"
     ]
    }
   ],
   "source": [
    "for region,site_id in site_region:\n",
    "    site_files_df_2019=files_df_2019[files_df_2019['site_id']==site_id]\n",
    "    region_files_df_2019=site_files_df_2019[site_files_df_2019['region']==region]\n",
    "    t=region_files_df_2019['timestamp'].sort_values()[0]\n",
    "    print(site_id,region,':',t.month,t.day,'(M/D)')\n",
    "    # print(region_files_df_2019['timestamp'].sort_values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2019, 5, 4)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only prudhoe and anwr filter others\n",
    "##### since they are only ones with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df = pd.read_pickle(str(file_properties_df_FilePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "230443"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_file_properties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2(df, key, value):\n",
    "    return df[df[key] == value]\n",
    "pd.DataFrame.mask2 = mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoe = merged_file_properties_df.mask2(\"region\",'prudhoe')\n",
    "anwr = merged_file_properties_df.mask2(\"region\",'anwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15778"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoe),len(anwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp = pd.concat([prudhoe,anwr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30466"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoeAndAnwr4photoExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp.to_pickle(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/enis/projects/nna/data/prudhoeAndAnwr4photoExp_dataV1.pkl'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = '/home/enis/tmp/dempster-11_1,0.pkl'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_clipping_2dict(\n",
    "    region_location_name,\n",
    "    clipping_results_path,\n",
    "    threshold: float = 1.0,\n",
    "    gathered_results=None,\n",
    "):\n",
    "    \"\"\"Load clipping results into a dictionary.\n",
    "file_properties_df, region_location_name,\n",
    "                                    clipping_results_path\n",
    "    \"\"\"\n",
    "    clipping_results_path = Path(clipping_results_path)\n",
    "    if not gathered_results:\n",
    "        gathered_results = {}\n",
    "    clipping_threshold_str = str(threshold)\n",
    "    clipping_threshold_str = clipping_threshold_str.replace(\".\", \",\")\n",
    "    file_name = (clipping_results_path /\n",
    "                 (region_location_name + f\"_{clipping_threshold_str}.pkl\"))\n",
    "    results_dict = np.load(file_name, allow_pickle=True)\n",
    "    results_dict = results_dict[()]\n",
    "    gathered_results.update(results_dict)  #type: ignore\n",
    "    return gathered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = np.load(ex, allow_pickle=True)\n",
    "results_dict = results_dict[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd=(list(results_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.append('/tank/data/nna/real/dempster/14/2020/S4A10424_20200812_160000.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping file for dempster-11_1,0.pkl exists at /home/enis/tmp. Checking existing results.\n",
      "1 number of files missing results, calculating only those.\n"
     ]
    }
   ],
   "source": [
    "from nna import clippingutils\n",
    "all_results_dict, files_w_errors = clippingutils.run_task_save(\n",
    "        asd,\n",
    "        'dempster-11',\n",
    "        '/home/enis/tmp',\n",
    "        1.0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_oswalk():\n",
    "    for root, dirnames, filenames in os.walk('/mnt/sdi/Spring/'):\n",
    "        for filename in filenames:\n",
    "            yield os.path.join(root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for f in find_files_oswalk():\n",
    "    all_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_set=set()\n",
    "counter=0\n",
    "for f in all_files:\n",
    "    last=f.split('.')[-1]\n",
    "    last_set.add(last)\n",
    "    if last=='wav':\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'SM4S', 'txt', 'wav'}, 7902)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_set,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-145b30d5bde8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-145b30d5bde8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    15468/\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "15468/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "516x30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
