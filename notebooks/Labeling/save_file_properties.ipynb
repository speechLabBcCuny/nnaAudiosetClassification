{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset,\n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change working directory\n",
    "os.chdir('/home/enis/projects/nna/notebooks/Labeling/')\n",
    "\n",
    "from savemetadata import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files in /tank/data/nna/real/anwr/31/2021/\n",
      "Found 563 files\n",
      "File extensions counts:\n",
      "Counter({'.flac': 563})\n",
      "\n",
      "\n",
      "563 new files, previously:  870 and total is 1433\n",
      "Processing new files:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 563/563 [00:00<00:00, 3285.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated metadata is saved to recordings_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "\n",
    "mock_args = [\n",
    "    '--search_path',\n",
    "    '/tank/data/nna/real/anwr/31/2021/',\n",
    "    '--search_parent_path',\n",
    "    '/tank/data/nna/real/',\n",
    "    '--previous_metadata_path',\n",
    "    './prev_recordings_metadata.csv',\n",
    "    '--ffprobe_path',\n",
    "    '/home/enis/sbin/ffprobe',\n",
    "    '--log_folder',\n",
    "    './logs/',\n",
    "]\n",
    "\n",
    "with patch('sys.argv', ['prog_name'] + mock_args):\n",
    "    args = parse_args()\n",
    "main_logic(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp recordings_metadata.csv prev_recordings_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region,location,recorder_id,duration_sec,start_date_time,end_date_time,file_path\n",
      "anwr,31,S4A10297,4438.0,2019-06-04T13:46:02.000000,2019-06-04T15:00:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-05-06T18:00:00.000000,2019-05-06T19:16:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-05-10T01:30:00.000000,2019-05-10T02:46:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-07-23T01:00:00.000000,2019-07-23T02:16:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-07-25T18:30:00.000000,2019-07-25T19:46:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-07-23T06:46:02.000000,2019-07-23T08:00:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-06-02T00:46:02.000000,2019-06-02T02:00:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-06-06T07:00:00.000000,2019-06-06T08:16:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-06-01T10:46:02.000000,2019-06-01T12:00:00.000000,\n"
     ]
    }
   ],
   "source": [
    "!head recordings_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n",
    "#V7: Counter({'.flac': 204692, '.aac': 9101, '.wav': 2340, '.mp3': 388, '.txt': 3, '.flac~': 1, '.filepart': 1})\n",
    "\n",
    "#V8: Counter({'.flac': 227227, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.filepart': 1, '.txt': 1})\n",
    "\n",
    "#V10: Counter({'.flac': 259798})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat(\n",
    "    [file_properties_df, current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \"2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_properties_df = pd.read_pickle(data_folder + pkl_file_name +\n",
    "                                            \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total days of recording 3536.5799098982093\n"
     ]
    }
   ],
   "source": [
    "print('total days of recording',\n",
    "      ((sum(current_file_properties_df['durationSec']) / 3600) / 24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "files_df_2019 = current_file_properties_df[current_file_properties_df['year'] ==\n",
    "                                           '2019']\n",
    "site_region = list({\n",
    "    (val[1], val[0]) for val in (files_df_2019[['locationId', 'region']].values)\n",
    "})\n",
    "site_region.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, site_id in site_region:\n",
    "    site_files_df_2019 = files_df_2019[files_df_2019['site_id'] == site_id]\n",
    "    region_files_df_2019 = site_files_df_2019[site_files_df_2019['region'] ==\n",
    "                                              region]\n",
    "    t = region_files_df_2019['timestamp'].sort_values()[0]\n",
    "    print(site_id, region, ':', t.month, t.day, '(M/D)')\n",
    "    # print(region_files_df_2019['timestamp'].sort_values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>locationId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_130002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 13:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220714_140002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-14 14:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220731_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-31 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_120000.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 12:00:00</td>\n",
       "      <td>3599.998549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220717_030002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-17 03:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220830_200002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-30 20:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220829_110004.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-29 11:00:04</td>\n",
       "      <td>3595.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220825_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-25 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220831_020002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-31 02:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220827_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-27 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16409 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   site_id locationId  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "...                                                    ...        ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "\n",
       "                                                             timestamp  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 13:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-14 14:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-31 09:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 12:00:00   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-17 03:00:02   \n",
       "...                                                                ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-30 20:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-29 11:00:04   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-25 09:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-31 02:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-27 09:00:02   \n",
       "\n",
       "                                                    durationSec  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3599.998549  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "...                                                         ...  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3595.998912  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "\n",
       "[16409 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df[['site_id', 'locationId', 'timestamp', 'durationSec']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the duration from seconds to hours\n",
    "file_properties_df['durationHours'] = file_properties_df['durationSec'] / 3600\n",
    "\n",
    "# Group by site_id and locationId, then sum the durations\n",
    "result = file_properties_df.groupby([\n",
    "    'site_id',\n",
    "])['durationHours'].sum().reset_index()\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/duration.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id  month  durationHours\n",
      "0       11      7     323.808829\n",
      "1       11      8     360.786849\n",
      "2       11      9      34.830630\n",
      "3       12      7     323.809384\n",
      "4       12      8     336.804094\n",
      "..     ...    ...            ...\n",
      "62      34      8     367.783506\n",
      "63      34      9       2.999442\n",
      "64      35      8     305.820790\n",
      "65      35      7     311.816896\n",
      "66      35      9       4.997773\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = file_properties_df.copy()\n",
    "# Convert timestamp column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract year and month\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Group by site_id, locationId, year and month, then sum the durations\n",
    "result = df.groupby(['site_id', 'month'])['durationHours'].sum().reset_index()\n",
    "\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/durations_bymonth.csv',\n",
    "              index=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expenv1",
   "language": "python",
   "name": "expenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
