{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset,\n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# change working directory\n",
    "os.chdir('/home/enis/projects/nna/notebooks/Labeling/')\n",
    "\n",
    "from savemetadata import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for files in /tank/data/nna/real/\n",
      "Found 287982 files\n",
      "File extensions counts:\n",
      "Counter({'.flac': 287562, '.mp3': 420})\n",
      "\n",
      "\n",
      "/scratch/enis/data/nna/database/metadata_V103.csv does NOT exists\n",
      "287982 new files, previously:  0 and total is 287982\n",
      "Processing new files:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/nna/notebooks/Labeling/savemetadata.py:128\u001b[0m, in \u001b[0;36mconcurrent_get_media_duration\u001b[0;34m(files, ffprobe_path, verbose)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[0;32m--> 128\u001b[0m     futures \u001b[39m=\u001b[39m {\n\u001b[1;32m    129\u001b[0m         executor\u001b[39m.\u001b[39msubmit(get_media_duration, file, ffprobe_path, verbose):\n\u001b[1;32m    130\u001b[0m         file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files\n\u001b[1;32m    131\u001b[0m     }\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Use the progress_wrapper for progress tracking\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/nna/notebooks/Labeling/savemetadata.py:129\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m    128\u001b[0m     futures \u001b[39m=\u001b[39m {\n\u001b[0;32m--> 129\u001b[0m         executor\u001b[39m.\u001b[39;49msubmit(get_media_duration, file, ffprobe_path, verbose):\n\u001b[1;32m    130\u001b[0m         file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files\n\u001b[1;32m    131\u001b[0m     }\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Use the progress_wrapper for progress tracking\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/concurrent/futures/thread.py:176\u001b[0m, in \u001b[0;36mThreadPoolExecutor.submit\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_work_queue\u001b[39m.\u001b[39mput(w)\n\u001b[0;32m--> 176\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_adjust_thread_count()\n\u001b[1;32m    177\u001b[0m \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/concurrent/futures/thread.py:182\u001b[0m, in \u001b[0;36mThreadPoolExecutor._adjust_thread_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_adjust_thread_count\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    181\u001b[0m     \u001b[39m# if idle threads are available, don't spin new threads\u001b[39;00m\n\u001b[0;32m--> 182\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_idle_semaphore\u001b[39m.\u001b[39;49macquire(timeout\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m):\n\u001b[1;32m    183\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/threading.py:467\u001b[0m, in \u001b[0;36mSemaphore.acquire\u001b[0;34m(self, blocking, timeout)\u001b[0m\n\u001b[1;32m    466\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    468\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/threading.py:316\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_waiters\u001b[39m.\u001b[39mappend(waiter)\n\u001b[0;32m--> 316\u001b[0m saved_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_release_save()\n\u001b[1;32m    317\u001b[0m gotit \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/threading.py:273\u001b[0m, in \u001b[0;36mCondition._release_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m<Condition(\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_waiters))\n\u001b[0;32m--> 273\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_release_save\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    274\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()           \u001b[39m# No state to save\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mwith\u001b[39;00m patch(\u001b[39m'\u001b[39m\u001b[39msys.argv\u001b[39m\u001b[39m'\u001b[39m, [\u001b[39m'\u001b[39m\u001b[39mprog_name\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m mock_args):\n\u001b[1;32m     17\u001b[0m     args \u001b[39m=\u001b[39m parse_args()\n\u001b[0;32m---> 18\u001b[0m main_logic(args)\n",
      "File \u001b[0;32m~/projects/nna/notebooks/Labeling/savemetadata.py:349\u001b[0m, in \u001b[0;36mmain_logic\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mNo new files found, exiting\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    348\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mProcessing new files:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m length_dict, files_werror \u001b[39m=\u001b[39m concurrent_get_media_duration(\n\u001b[1;32m    350\u001b[0m     new_files_path_list, ffprobe_path, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    352\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(files_werror) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    353\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthere are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(files_werror)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\n\u001b[1;32m    354\u001b[0m           \u001b[39m'\u001b[39m\u001b[39m number of files with errors reading length via ffprobe\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/projects/nna/notebooks/Labeling/savemetadata.py:127\u001b[0m, in \u001b[0;36mconcurrent_get_media_duration\u001b[0;34m(files, ffprobe_path, verbose)\u001b[0m\n\u001b[1;32m    125\u001b[0m files_werror \u001b[39m=\u001b[39m []\n\u001b[1;32m    126\u001b[0m length_dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 127\u001b[0m \u001b[39mwith\u001b[39;00m concurrent\u001b[39m.\u001b[39mfutures\u001b[39m.\u001b[39mThreadPoolExecutor() \u001b[39mas\u001b[39;00m executor:\n\u001b[1;32m    128\u001b[0m     futures \u001b[39m=\u001b[39m {\n\u001b[1;32m    129\u001b[0m         executor\u001b[39m.\u001b[39msubmit(get_media_duration, file, ffprobe_path, verbose):\n\u001b[1;32m    130\u001b[0m         file \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files\n\u001b[1;32m    131\u001b[0m     }\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Use the progress_wrapper for progress tracking\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/concurrent/futures/_base.py:649\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 649\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshutdown(wait\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    650\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         t\u001b[39m.\u001b[39;49mjoin()\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot join current thread\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_wait_for_tstate_lock()\n\u001b[1;32m   1097\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1098\u001b[0m     \u001b[39m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[39m=\u001b[39m\u001b[39mmax\u001b[39m(timeout, \u001b[39m0\u001b[39m))\n",
      "File \u001b[0;32m/scratch/enis/conda/envs/expenv1/lib/python3.10/threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1116\u001b[0m     \u001b[39mif\u001b[39;00m lock\u001b[39m.\u001b[39;49macquire(block, timeout):\n\u001b[1;32m   1117\u001b[0m         lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m   1118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from unittest.mock import patch\n",
    "\n",
    "mock_args = [\n",
    "    '--search_path', '/tank/data/nna/real/', '--search_parent_path',\n",
    "    '/tank/data/nna/real/', '--previous_metadata_path',\n",
    "    '/scratch/enis/data/nna/database/metadata_V103.csv', '--ffprobe_path',\n",
    "    '/home/enis/sbin/ffprobe', '--log_folder', './logs/',\n",
    "    '--search_ignore_folders', \"/tank/data/nna/real/stinchcomb/dups/\",\n",
    "    \"/tank/data/nna/real/stinchcomb/excerpts/\",\n",
    "    \"/tank/data/nna/real/stinchcomb/\"\n",
    "]\n",
    "\n",
    "with patch('sys.argv', ['prog_name'] + mock_args):\n",
    "    args = parse_args()\n",
    "main_logic(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp recordings_metadata.csv prev_recordings_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region,location,recorder_id,duration_sec,start_date_time,end_date_time,file_path\n",
      "anwr,31,S4A10297,4438.0,2019-06-04T13:46:02.000000,2019-06-04T15:00:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-05-06T18:00:00.000000,2019-05-06T19:16:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-05-10T01:30:00.000000,2019-05-10T02:46:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-07-23T01:00:00.000000,2019-07-23T02:16:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-07-25T18:30:00.000000,2019-07-25T19:46:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-07-23T06:46:02.000000,2019-07-23T08:00:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-06-02T00:46:02.000000,2019-06-02T02:00:00.000000,\n",
      "anwr,31,S4A10297,4560.0,2019-06-06T07:00:00.000000,2019-06-06T08:16:00.000000,\n",
      "anwr,31,S4A10297,4438.0,2019-06-01T10:46:02.000000,2019-06-01T12:00:00.000000,\n"
     ]
    }
   ],
   "source": [
    "!head recordings_metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n",
    "#V7: Counter({'.flac': 204692, '.aac': 9101, '.wav': 2340, '.mp3': 388, '.txt': 3, '.flac~': 1, '.filepart': 1})\n",
    "\n",
    "#V8: Counter({'.flac': 227227, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.filepart': 1, '.txt': 1})\n",
    "\n",
    "#V10: Counter({'.flac': 259798})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat(\n",
    "    [file_properties_df, current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_file_properties_df.to_pickle(data_folder + pkl_file_name + \"2.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check dataset stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_file_properties_df = pd.read_pickle(data_folder + pkl_file_name +\n",
    "                                            \".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total days of recording 3536.5799098982093\n"
     ]
    }
   ],
   "source": [
    "print('total days of recording',\n",
    "      ((sum(current_file_properties_df['durationSec']) / 3600) / 24))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "files_df_2019 = current_file_properties_df[current_file_properties_df['year'] ==\n",
    "                                           '2019']\n",
    "site_region = list({\n",
    "    (val[1], val[0]) for val in (files_df_2019[['locationId', 'region']].values)\n",
    "})\n",
    "site_region.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region, site_id in site_region:\n",
    "    site_files_df_2019 = files_df_2019[files_df_2019['site_id'] == site_id]\n",
    "    region_files_df_2019 = site_files_df_2019[site_files_df_2019['region'] ==\n",
    "                                              region]\n",
    "    t = region_files_df_2019['timestamp'].sort_values()[0]\n",
    "    print(site_id, region, ':', t.month, t.day, '(M/D)')\n",
    "    # print(region_files_df_2019['timestamp'].sort_values()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>locationId</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>durationSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_130002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 13:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220714_140002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-14 14:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220731_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-31 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220815_120000.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-15 12:00:00</td>\n",
       "      <td>3599.998549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/11/2022/S4A10276_20220717_030002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-07-17 03:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220830_200002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-30 20:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220829_110004.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-29 11:00:04</td>\n",
       "      <td>3595.998912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220825_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-25 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220831_020002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-31 02:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/nna/recover_files/2022/region/35/2022/S4A10272_20220827_090002.wav</th>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022-08-27 09:00:02</td>\n",
       "      <td>3597.995828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16409 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   site_id locationId  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...    2022       2022   \n",
       "...                                                    ...        ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...    2022       2022   \n",
       "\n",
       "                                                             timestamp  \\\n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 13:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-14 14:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-31 09:00:02   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-08-15 12:00:00   \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1... 2022-07-17 03:00:02   \n",
       "...                                                                ...   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-30 20:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-29 11:00:04   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-25 09:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-31 02:00:02   \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1... 2022-08-27 09:00:02   \n",
       "\n",
       "                                                    durationSec  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3599.998549  \n",
       "data/nna/recover_files/2022/region/11/2022/S4A1...  3597.995828  \n",
       "...                                                         ...  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3595.998912  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "data/nna/recover_files/2022/region/35/2022/S4A1...  3597.995828  \n",
       "\n",
       "[16409 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties_df[['site_id', 'locationId', 'timestamp', 'durationSec']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the duration from seconds to hours\n",
    "file_properties_df['durationHours'] = file_properties_df['durationSec'] / 3600\n",
    "\n",
    "# Group by site_id and locationId, then sum the durations\n",
    "result = file_properties_df.groupby([\n",
    "    'site_id',\n",
    "])['durationHours'].sum().reset_index()\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/duration.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   site_id  month  durationHours\n",
      "0       11      7     323.808829\n",
      "1       11      8     360.786849\n",
      "2       11      9      34.830630\n",
      "3       12      7     323.809384\n",
      "4       12      8     336.804094\n",
      "..     ...    ...            ...\n",
      "62      34      8     367.783506\n",
      "63      34      9       2.999442\n",
      "64      35      8     305.820790\n",
      "65      35      7     311.816896\n",
      "66      35      9       4.997773\n",
      "\n",
      "[67 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "df = file_properties_df.copy()\n",
    "# Convert timestamp column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract year and month\n",
    "df['year'] = df['timestamp'].dt.year\n",
    "df['month'] = df['timestamp'].dt.month\n",
    "\n",
    "# Group by site_id, locationId, year and month, then sum the durations\n",
    "result = df.groupby(['site_id', 'month'])['durationHours'].sum().reset_index()\n",
    "\n",
    "result.sort_values(by='site_id', ascending=True, inplace=True)\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(result)\n",
    "\n",
    "result.to_csv('/tank/data/nna/recover_files/2022/durations_bymonth.csv',\n",
    "              index=False)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2022])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expenv1",
   "language": "python",
   "name": "expenv1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
