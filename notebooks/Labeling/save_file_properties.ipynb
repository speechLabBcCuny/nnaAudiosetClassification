{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Collects data for file_properties_df.\\n\\nfile_properties_df holds metadata about data in our dataset, \\ndetails of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Collects data for file_properties_df.\n",
    "\n",
    "file_properties_df holds metadata about data in our dataset, \n",
    "details of metadata can be seen at src/nna/tests/mock_data.py::mock_file_properties_df\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nna.fileUtils import list_files,getLength,read_file_properties_v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Programs\n",
    "# ffprobe version >= 4.3.1  \n",
    "ffprobe_path = '/scratch/enis/conda/envs/speechEnv/bin/ffprobe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS for new DATABASE\n",
    "\n",
    "# increase version number accordinly \n",
    "previous_database_ver_str = 'V5'\n",
    "new_database_ver_str = 'V6'\n",
    "\n",
    "# where to save txt file storing length info\n",
    "# old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "data_folder = '/scratch/enis/data/nna/database/'\n",
    "#/scratch/enis/data/nna/database\n",
    "\n",
    "# path to search for audio files\n",
    "# where\n",
    "# ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "search_path=\"/tank/data/nna/real/\"\n",
    "\n",
    "ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PARAMETERS for external or small inferences\n",
    "\n",
    "# # PARAMETERS  \n",
    "\n",
    "# # increase version number accordinly \n",
    "# previous_database_ver_str = ''\n",
    "# new_database_ver_str = 'V1'\n",
    "\n",
    "# # where to save txt file storing length info\n",
    "# # old_data_folder=\"/home/enis/projects/nna/data/\"\n",
    "# # data_folder = '/scratch/enis/data/nna/database/'\n",
    "# data_folder = '/scratch/enis/data/nna/collar_database/'\n",
    "\n",
    "# #/scratch/enis/data/nna/database\n",
    "\n",
    "# # path to search for audio files\n",
    "# # where\n",
    "# # ignore_folders=['/tank/data/nna/real/stinchcomb/']\n",
    "\n",
    "# # search_path=\"/tank/data/nna/real/\"\n",
    "# search_path = '/tank/data/nna/audio_collars/'\n",
    "\n",
    "# ignore_folders=[\"/tank/data/nna/real/stinchcomb/dups/\",\"/tank/data/nna/real/stinchcomb/excerpts/\"]\n",
    "# # search_path=\"/tank/data/nna/real/stinchcomb/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Relative Path names\n",
    "\n",
    "# if we already have a list of files we can load them \n",
    "# files_list_path=data_folder+\"stinchcomb_files_pathV1.txt\"\n",
    "files_list_path=data_folder+ f\"allFields_path{new_database_ver_str}.txt\"\n",
    "\n",
    "# if we calculated audio lengths and saved them into text file, \n",
    "# we can load them\n",
    "fileswlen_path = data_folder+ f\"allFields_wlen_f{new_database_ver_str}.txt\"\n",
    "filesWError_out = data_folder+f\"allFields_wERROR_f{new_database_ver_str}.txt\"\n",
    "\n",
    "# do NOT add pkl extension at the end\n",
    "pkl_file_name=f\"allFields_data{new_database_ver_str}\"\n",
    "\n",
    "\n",
    "# this is the current info we have so we can check if we already processed a file before\n",
    "current_pkl_file = data_folder + f\"allFields_data{previous_database_ver_str}.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.99 s, sys: 840 ms, total: 2.83 s\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Find files\n",
    "# in given search path ignoring given directories\n",
    "if not Path(fileswlen_path).exists():\n",
    "    files_path_list=list_files(search_path,ignore_folders)\n",
    "else:\n",
    "    with open(files_list_path,\"r\") as f:\n",
    "        lines=f.readlines()\n",
    "        files_path_list=[line.strip() for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example file /tank/data/nna/real/anwr/31/2019/S4A10297_20190504_000000.flac\n"
     ]
    }
   ],
   "source": [
    "print('example file',files_path_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(files_path_list[0]).is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})\n"
     ]
    }
   ],
   "source": [
    "# count file extension and filter if required\n",
    "\n",
    "files_suffixes=[]\n",
    "files_path_list_filtered=[]\n",
    "for m in files_path_list:\n",
    "    m=Path(m)\n",
    "    if m.is_dir():\n",
    "        continue\n",
    "    mSuffix = m.suffix.lower()\n",
    "    \n",
    "    files_suffixes.append(mSuffix)\n",
    "    m_str=str(m).lower()\n",
    "    if \"~\" in m_str:\n",
    "        continue\n",
    "    if \"filepart\" in m_str:\n",
    "        continue\n",
    "    if \".txt\" in m_str:\n",
    "        continue\n",
    "#     if mSuffix!=\".flac\" and mSuffix!=\".aac\" and mSuffix!=\".mp3\":\n",
    "#         print(m)\n",
    "#         break\n",
    "    files_path_list_filtered.append((m))\n",
    "        \n",
    "print(Counter(files_suffixes))\n",
    "files_path_list = files_path_list_filtered[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/enis/data/nna/collar_database/allFields_data.pkl'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#V4: Counter({'.flac': 112053, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V5: Counter({'.flac': 151527, '.aac': 9101, '.mp3': 388, '.flac~': 1})\n",
    "#V6: Counter({'.flac': 165976, '.aac': 9101, '.mp3': 388, '.flac~': 1, '.txt': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('new', 14450, 'previously', 161015, 'total', 175465)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Load previous data\n",
    "if Path(current_pkl_file).exists() :\n",
    "\n",
    "    current_file_properties_df=pd.read_pickle(str(current_pkl_file))\n",
    "\n",
    "    # remove files we already know about\n",
    "    currentFileSet = set(current_file_properties_df.index)\n",
    "    foundFileSet = set(files_path_list)\n",
    "    foundFileSet = foundFileSet.difference(currentFileSet)\n",
    "    New_files_path_list = list(foundFileSet)\n",
    "    a_str=\"new\",len(New_files_path_list),\"previously\",len(currentFileSet),\"total\",len(files_path_list)\n",
    "    print(a_str)\n",
    "else:\n",
    "    print('does NOT exists',current_pkl_file)\n",
    "    New_files_path_list = files_path_list[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New_files_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR file is too short /tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac\n",
      "command run with ERROR: ['/scratch/enis/conda/envs/speechEnv/bin/ffprobe', '-i', '/tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac', '-show_entries', 'format=duration', '-v', 'quiet']\n"
     ]
    }
   ],
   "source": [
    "# Load or calculate Audio length\n",
    "import subprocess\n",
    "\n",
    "filesWError = []\n",
    "\n",
    "# learn length of each audio and store in a text file, \n",
    "# if file already exists, it tries to get data from there\n",
    "if not Path(fileswlen_path).exists():\n",
    "    length_dict={}\n",
    "    for f in New_files_path_list:\n",
    "#         length=float(getLength(f))\n",
    "##################\n",
    "        input_video = f\n",
    "        \n",
    "        cmd=[]\n",
    "        cmd.extend( [ffprobe_path, '-i', '{}'.format(input_video), '-show_entries' ,'format=duration', '-v', 'quiet' ])\n",
    "        result = subprocess.Popen(cmd, stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "        output = result.communicate(b'\\n')\n",
    "        output = [i.decode('ascii') for i in output]\n",
    "        if output[0]==\"\":\n",
    "            length = -1\n",
    "            print(\"ERROR file is too short {}\".format(input_video))\n",
    "            print(\"command run with ERROR: {}\".format(cmd))\n",
    "            filesWError.append(input_video)\n",
    "        else:\n",
    "            length = output[0].split(\"\\n\")[1].split(\"=\")[1]\n",
    "###############\n",
    "        length_dict[f]=length\n",
    "\n",
    "    length_list=list(length_dict.items())\n",
    "    Path(fileswlen_path).parent.mkdir(parents=True,exist_ok=True)\n",
    "    with open(fileswlen_path,\"w\") as f:\n",
    "        for line in length_list:\n",
    "            join_lines = [str(i) for i in line]\n",
    "            f.write(\",\".join(join_lines)+\"\\n\")\n",
    "\n",
    "with open(fileswlen_path,\"r\") as f:\n",
    "    lines=f.readlines()\n",
    "    fileswlen=[line.strip().split(\",\") for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/tank/data/nna/real/dalton/04/2019/S4A10281_A_Summary.aac')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filesWError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# print and save files with errors\n",
    "\n",
    "print(len(filesWError))\n",
    "with open(filesWError_out,\"w\") as f:\n",
    "    for line in length_list:\n",
    "        join_lines = [str(i) for i in line]\n",
    "        f.write(\",\".join(join_lines)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn results into a dict\n",
    "fileswlen=dict([(i[0],float(i[1])) for i in fileswlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties\n",
    "file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14450)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exceptions),len(New_files_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/tank/data/nna/real/prudhoe/12/2021/S4A10265_20210706_060002.flac')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_files_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2timestamp(fileinfo_dict):\n",
    "    # x=file_properties[file]\n",
    "    #         print(x)\n",
    "    hour_min_sec = fileinfo_dict[\"hour_min_sec\"]\n",
    "    hour = int(hour_min_sec[:2])\n",
    "    minute = int(hour_min_sec[2:4])\n",
    "    second = int(hour_min_sec[4:6])\n",
    "    year = int(fileinfo_dict[\"year\"])\n",
    "\n",
    "    timestamp = datetime.datetime(year,\n",
    "                                  int(fileinfo_dict[\"month\"]),\n",
    "                                  int(fileinfo_dict[\"day\"]),\n",
    "                                  hour=hour,\n",
    "                                  minute=minute,\n",
    "                                  second=second,\n",
    "                                  microsecond=0)\n",
    "    fileinfo_dict[\"timestamp\"] = timestamp\n",
    "    return fileinfo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_id': '12',\n",
       " 'locationId': '12',\n",
       " 'site_name': '',\n",
       " 'recorderId': 'S4A10265',\n",
       " 'hour_min_sec': '060002',\n",
       " 'year': '2021',\n",
       " 'month': '07',\n",
       " 'day': '06',\n",
       " 'region': 'prudhoe',\n",
       " 'timestamp': datetime.datetime(2021, 7, 6, 6, 0, 2)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_properties[Path('/tank/data/nna/real/prudhoe/12/2021/S4A10265_20210706_060002.flac')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hard code file_path\n",
    "# file_properties = {}\n",
    "\n",
    "# for apath in New_files_path_list:\n",
    "#     startDateTime=apath.stem.split('_')\n",
    "#     date = startDateTime[0]\n",
    "#     year, month, day = date[0:4], date[4:6], date[6:8]\n",
    "#     hour_min_sec = startDateTime[1]\n",
    "\n",
    "#     # location_id = '149'\n",
    "#     # if '721' in str(apath):\n",
    "#     #     region = '721'\n",
    "#     # elif '781' in str(apath):\n",
    "#     #     region = '781'\n",
    "    \n",
    "#     site_name=''\n",
    "#     recorderId=''\n",
    "#     file_properties[apath] = str2timestamp({\n",
    "#                     \"site_id\": location_id,\n",
    "#                     \"locationId\": location_id,\n",
    "#                     \"site_name\": site_name,\n",
    "#                     \"recorderId\": recorderId,\n",
    "#                     \"hour_min_sec\": hour_min_sec,\n",
    "#                     \"year\": year,\n",
    "#                     \"month\": month,\n",
    "#                     \"day\": day,\n",
    "#                     \"region\": region\n",
    "#                 })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties,exceptions = read_file_properties_v2(New_files_path_list,debug=0)\n",
    "for f,lengthSeconds in fileswlen.items():\n",
    "    if file_properties.get(Path(f)) is not None:\n",
    "        file_properties[Path(f)][\"durationSec\"] = lengthSeconds\n",
    "        file_properties[Path(f)][\"timestampEnd\"] = file_properties[Path(f)][\"timestamp\"] + datetime.timedelta(seconds=lengthSeconds)\n",
    "file_properties_df=pd.DataFrame(file_properties).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df = file_properties_df[file_properties_df['durationSec']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with previous file properties\n",
    "merged_file_properties_df = pd.concat([file_properties_df,current_file_properties_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_properties_df.to_pickle(data_folder+pkl_file_name+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep only prudhoe and anwr filter others\n",
    "##### since they are only ones with images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df = pd.read_pickle(str(file_properties_df_FilePath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121541"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(merged_file_properties_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2(df, key, value):\n",
    "    return df[df[key] == value]\n",
    "pd.DataFrame.mask2 = mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoe = merged_file_properties_df.mask2(\"region\",'prudhoe')\n",
    "anwr = merged_file_properties_df.mask2(\"region\",'anwr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15778"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoe),len(anwr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp = pd.concat([prudhoe,anwr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30466"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prudhoeAndAnwr4photoExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "prudhoeAndAnwr4photoExp.to_pickle(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/enis/projects/nna/data/prudhoeAndAnwr4photoExp_dataV1.pkl'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_folder+\"prudhoeAndAnwr4photoExp_dataV1\"+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = '/home/enis/tmp/dempster-11_1,0.pkl'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_clipping_2dict(\n",
    "    region_location_name,\n",
    "    clipping_results_path,\n",
    "    threshold: float = 1.0,\n",
    "    gathered_results=None,\n",
    "):\n",
    "    \"\"\"Load clipping results into a dictionary.\n",
    "file_properties_df, region_location_name,\n",
    "                                    clipping_results_path\n",
    "    \"\"\"\n",
    "    clipping_results_path = Path(clipping_results_path)\n",
    "    if not gathered_results:\n",
    "        gathered_results = {}\n",
    "    clipping_threshold_str = str(threshold)\n",
    "    clipping_threshold_str = clipping_threshold_str.replace(\".\", \",\")\n",
    "    file_name = (clipping_results_path /\n",
    "                 (region_location_name + f\"_{clipping_threshold_str}.pkl\"))\n",
    "    results_dict = np.load(file_name, allow_pickle=True)\n",
    "    results_dict = results_dict[()]\n",
    "    gathered_results.update(results_dict)  #type: ignore\n",
    "    return gathered_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = np.load(ex, allow_pickle=True)\n",
    "results_dict = results_dict[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd=(list(results_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1384"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd.append('/tank/data/nna/real/dempster/14/2020/S4A10424_20200812_160000.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clipping file for dempster-11_1,0.pkl exists at /home/enis/tmp. Checking existing results.\n",
      "1 number of files missing results, calculating only those.\n"
     ]
    }
   ],
   "source": [
    "from nna import clippingutils\n",
    "all_results_dict, files_w_errors = clippingutils.run_task_save(\n",
    "        asd,\n",
    "        'dempster-11',\n",
    "        '/home/enis/tmp',\n",
    "        1.0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files_oswalk():\n",
    "    for root, dirnames, filenames in os.walk('/mnt/sdi/Spring/'):\n",
    "        for filename in filenames:\n",
    "            yield os.path.join(root, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for f in find_files_oswalk():\n",
    "    all_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_set=set()\n",
    "counter=0\n",
    "for f in all_files:\n",
    "    last=f.split('.')[-1]\n",
    "    last_set.add(last)\n",
    "    if last=='wav':\n",
    "        counter+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'SM4S', 'txt', 'wav'}, 7902)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_set,counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-20-145b30d5bde8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-145b30d5bde8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    15468/\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "15468/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "516x30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
